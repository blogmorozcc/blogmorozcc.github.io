[{"content":"Що таке Docker і Docker Compose Docker і Docker Compose — це інструменти, призначені для спрощення процесу керування та розгортання програм у контейнерах. Ось огляд кожного з них, а також їхні відмінності та основні переваги.\nDocker Визначення:\nDocker — це платформа, яка використовує контейнеризацію для розгортання, керування та запуску програм. Контейнери — це легкі, портативні та узгоджені середовища, які містять усе необхідне для запуску частини програмного забезпечення, наприклад код, середовище виконання, системні інструменти, бібліотеки та налаштування.\nКлючові переваги:\nУзгодженість: Docker гарантує, що програмне забезпечення працюватиме однаково незалежно від того, де воно розгорнуто, оскільки контейнери інкапсулюють усі залежності. Ізоляція: контейнери працюють в ізольованих середовищах, що полегшує керування залежностями та уникнення конфліктів. Портативність: контейнери можуть працювати в будь-якій системі, яка підтримує Docker, включаючи локальні сервери, публічні хмари та персональні машини. Ефективність: контейнери Docker легкі та мають менші витрати порівняно з традиційними віртуальними машинами. Масштабованість: Docker дозволяє легко масштабувати додатки по горизонталі, запускаючи кілька контейнерів на різних хостах. Docker Compose Визначення:\nDocker Compose — це інструмент для визначення та запуску багатоконтейнерних програм Docker. Він використовує файл YAML для налаштування служб програми, мереж і томів, що дозволяє вам керувати декількома контейнерами як однією програмою.\nКлючові переваги:\nСпрощена конфігурація: Docker Compose використовує один файл YAML (docker-compose.yml) для налаштування всіх служб вашої програми, що полегшує керування та розуміння. Керування кількома контейнерами: дозволяє визначати, запускати та керувати кількома взаємопов’язаними контейнерами за допомогою однієї команди (docker-compose up). Послідовність середовища: забезпечує узгоджене середовище на різних етапах розробки, тестування та виробництва за допомогою того самого файлу конфігурації. Мережа: автоматично налаштовує мережу, щоб контейнери могли спілкуватися один з одним без додаткового налаштування. Керування томами: спрощує налаштування та керування томами даних, якими можна спільно користуватися між контейнерами. Відмінності Сфера застосування: Docker використовується для одноконтейнерних програм, тоді як Docker Compose розроблено для програм, що складаються з кількох контейнерів. Використання: команди Docker (docker run, docker build тощо) використовуються для керування окремими контейнерами, тоді як команди Docker Compose (docker-compose up, docker-compose down тощо) керують цілими багатоконтейнерними програмами, визначеними в YAML. файл. Конфігурація: Docker використовує Dockerfiles для визначення зображень контейнерів, тоді як Docker Compose використовує файл docker-compose.yml для визначення багатоконтейнерних програм, включаючи їхні мережі та томи. Комбіновані ключові переваги\nОптимізована розробка: разом Docker і Docker Compose дозволяють швидко й узгоджено розробляти, тестувати та розгортати програми. Відтворюваність: обидва інструменти гарантують, що середовище, в якому працює програма, є узгодженим на різних етапах, зменшуючи проблему \u0026ldquo;це працює на моїй машині\u0026rdquo;. Спрощений CI/CD: інтеграція з конвеєрами CI/CD стає легшою, оскільки контейнери можна використовувати для запуску тестів і розгортання програм у узгодженому середовищі. Ефективність використання ресурсів: контейнери використовують те саме ядро ​​ОС і можуть бути більш ефективними за використання ресурсів, ніж віртуальні машини. Приклад Припустімо, що у вас є веб-програма з такими компонентами:\nвеб-сервер (наприклад, Nginx) сервер додатків (наприклад, Node.js) база даних (наприклад, PostgreSQL) З Docker:\nВи створюєте окремі файли Docker для кожного компонента, щоб контейнерувати їх. З Docker Compose:\nВи створюєте файл docker-compose.yml, щоб визначити всі три служби та їх взаємодію. Ви можете відкрити весь стек за допомогою однієї команди (docker-compose up). Встановлення Docker Перш за все оновіть системні пакети до останніх версій:\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade Потім встановіть необхідні пакети:\nsudo apt install apt-transport-https ca-certificates curl software-properties-common gnupg2 Додайте відкритий ключ GPG для офіційного репозиторію Docker:\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - Додайте репозиторій Docker debian до списку джерел менеджера пакетів apt:\necho \u0026#34;deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list Оновіть індекси пакетів і встановіть Docker Community Edition:\nsudo apt update \u0026amp;\u0026amp; sudo apt install docker-ce Увімкніть і запустіть демон docker systemd:\nsudo systemctl enable --now docker Нарешті перевірте інсталяцію, запустивши демонстраційний контейнер hello-world:\nsudo docker run hello-world Встановлення Docker Compose Завантажте останню версію з офіційного репозиторію:\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose Додайте дозволи на виконання до завантаженого двійкового файлу:\nsudo chmod +x /usr/local/bin/docker-compose Перевірте встановлення, роздрукувавши версію Docker Compose:\ndocker compose --version Крім того, ви можете створити тестовий файл docker-compose.yml з декількома демонстраційними службами (наприклад, веб-сервер і база даних):\n1 2 3 4 5 6 7 8 9 10 version: \u0026#39;3\u0026#39; services: web: image: nginx ports: - \u0026#34;80:80\u0026#34; database: image: postgres environment: POSTGRES_PASSWORD: example А потім, щоб запустити його, використовуйте команду:\ndocker compose up Висновок У цьому прикладі показано, як інсталювати Docker і Docker Compose у системі Debian, щоб вони доповнювали один одного під час розробки, розгортання та ефективного керування програмами.\n","date":"2024-06-03T00:00:00Z","image":"http://localhost:1313/post/what-is-docker-and-docker-compose-and-how-to-install-and-use-it-on-debian/header_hub514da7001493284666285be454a18d2_432280_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D1%89%D0%BE-%D1%82%D0%B0%D0%BA%D0%B5-docker-%D1%96-docker-compose-%D1%96-%D1%8F%D0%BA-%D1%97%D1%85-%D0%B2%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%B8%D1%82%D0%B8-%D0%BD%D0%B0-debian/","title":"Що таке Docker і Docker Compose і як їх встановити на Debian"},{"content":"Вступ Stable Diffusion — це модель глибокого навчання з текстом у зображення, розроблена Stability AI, що використовується для створення детальних зображень на основі текстових підказок. Модель належить до класу генеративних моделей, званих дифузійними моделями, які ітеративно знімають шум у випадковому сигналі для отримання зображення. AUTOMATIC1111 відноситься до популярної реалізації веб-інтерфейсу користувача (UI) для взаємодії із Stable Diffusion. Він забезпечує надійний і зручний спосіб використання можливостей Stable Diffusion.\nЧому я запускаю AUTOMATIC1111 у віртуальній машині В одній із моїх попередніх статей я згадав, що використовую ПК з двома відеокартами AMD, використовує Arch Linux в якості основної ОС. Особисто для мене запуск AUTOMATIC1111 у віртуальній машині на базі KVM із прокиданням відеокарти AMD має кілька ключових переваг:\nПортативність. Оскільки я використовую Arch Linux як свою основну хост-ОС на різних комп’ютерах, інколи буває складно керувати залежностями, необхідними для запуску AUTOMATIC1111. Наприклад, на момент написання цієї статті (02.06.2024) для AUTOMATIC1111 потрібен Python 3.10, а найновішою версією Python в офіційних репозиторіях arch є Python 3.12. У разі запуску AUTOMATIC1111 усередині віртуальної машини я можу налаштувати залежності всередині цієї віртуальної машини, і мені не потрібно турбуватися про те, що залежності потенційно стануть некоректними після оновлення Arch.\nРезервне копіювання. Оскільки я маю сховище віртуальної машини як один файл *.qcow2, я можу створити його резервну копію, перенести на іншу машину чи сервер у своїй домашній лабораторії. Також легко зберігати файли AI моделей та LORA в cховищі віртуальної машини, і якщо мені потрібно перенести інсталяцію AUTOMATIC1111 на іншу реальну машину, мені потрібно лише скопіювати резервну копію віртуальної машини. Немає необхідності кожного разу встановлювати залежності, налаштовувати моделі.\nДля чого мені потрібен AUTOMATIC1111 Програмне забезпечення AUTOMATIC1111 дуже важливе для моєї роботи, оскільки я розробляю безкоштовний open soruce додаток SDAI - Android Stable Diffusion, який можна підключати до будь-якого сервера AUTOMATIC1111 або іншого підтримуваного провайдера генерації зображень. Мені потрібно багато різних ізольованих віртуальних серверів AUTOMATIC1111 для тестування мого Android додатку.\nВстановлення Створення нової віртуальної машини Linux Спочатку нам потрібно створити нову віртуальну машину Linux із пропуском GPU пристроїв PCI до цієї віртуальної машини. Я вже розповідав про створення віртуальної машини в статті \u0026ldquo;GPU PCI passthrough to Windows KVM on Arch Linux\u0026rdquo;, але цього разу я використовуватиму Ubuntu Sever 22.04 LTS як ОС для гостьової ВМ. Я вибрав Ubuntu Server 22.04 для гостьової ОС, тому що на момент написання цієї статті (02.06.2024) це остання версія, яка підтримується пропрієтарним драйвером AMD ROCM, який необхідний для запуску штучного інтелекту на потужності GPU.\nОновіть пакети ОС Після встановлення ОС перше, що вам потрібно зробити, це оновити системні пакети до останніх доступних версій.\n1 2 sudo apt update sudo apt upgrade Встановіть необхідні пакети sudo apt install -y git python3-pip python3-venv python3-dev libstdc++-12-dev libgl1-mesa-glx Встановлення драйвера AMD ROCM Я використав офіційні інструкції з документації AMD, щоб встановити драйвер ROCM.\nСпочатку встановіть заголовки та додаткові компоненти для поточного ядра:\nsudo apt install -y \u0026#34;linux-headers-$(uname -r)\u0026#34; \u0026#34;linux-modules-extra-$(uname -r)\u0026#34; Потім переконайтеся, що ваш поточний користувач включений до груп video і render. Щоб додати поточного користувача до груп, використовуйте команду:\nsudo usermod -a -G render,video $LOGNAME Завантажте інсталяційний пакет deb і встановіть його:\nwget https://repo.radeon.com/amdgpu-install/6.1.1/ubuntu/jammy/amdgpu-install_6.1.60101-1_all.deb sudo dpkg -i amdgpu-install_6.1.60101-1_all.deb Встановіть модуль DKMS і пакети rocm:\nsudo apt update sudo apt install amdgpu-dkms rocm Нарешті, перезавантажте віртуальну машину:\nsudo reboot Встановлення AUTOMATIC1111 Найпростіший і зручний спосіб - просто клонувати офіційний репозиторій git. Після клонування перейдіть до клонованого каталогу.\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui cd stable-diffusion-webui Налаштуйте віртуальне середовище Python:\npython3 -m venv venv source venv/bin/activate Встановіть залежності python, необхідні AUTOMATIC1111:\npip3 install -r requirements.txt Видаліть стандартні залежності torch та замініть їх на ROCM:\npip3 uninstall torch torchvision pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0 Створіть скрипт запуску AUTOMATIC1111 Я буду використовувати nano для створення нового файлу nano launch.sh.\n1 2 3 4 5 6 7 8 9 #!/bin/sh source venv/bin/activate export HSA_OVERRIDE_GFX_VERSION=10.3.0 export HIP_VISIBLE_DEVICES=0 export PYTORCH_HIP_ALLOC_CONF=garbage_collection_threshold:0.8,max_split_size_mb:512 python3 launch.py --api --listen --enable-insecure-extension-access --opt-sdp-attention Потім збережіть файл Ctrl + O і вийдіть з nano Ctrl + X.\nЗапуск AUTOMATIC1111 Кожного разу, коли вам потрібно запустити AUTOMATIC1111, перейдіть до склонованого каталогу stable-diffusion-webui і запустіть створений сценарій launch.sh, як у наступному прикладі:\ncd stable-diffusion-webui bash launch.sh У результаті ви побачите, що AUTOMATIC1111 працює.\nВисновок Stable Diffusion — це потужна модель для створення зображень із текстових описів, а AUTOMATIC1111 — це зручний інтерфейс, який полегшує ефективне використання можливостей Stable Diffusion. Разом вони забезпечують широкий спектр творчих і практичних застосувань у сфері генеративного мистецтва та синтезу зображень. Використовуючи віртуальну машину на основі KVM із прокинутим графічним адаптером AMD, ви можете створити потужне, безпечне та гнучке середовище для запуску AUTOMATIC1111 і ефективного використання можливостей Stable Diffusion.\nПосилання Ubuntu Sever 22.04 LTS Jammy AMD ROCM Документація AUTOMATIC1111 SDAI - Stable Diffusion Android додаток Кастомний скрипт запуску stable-diffusion-webui ","date":"2024-06-01T00:00:00Z","image":"http://localhost:1313/post/how-to-run-stable-diffusion-in-vm-on-amd-gpu-automatic1111--kvm--gpu-passthrough/header_hu3aafa9004173c931941da8e2c440d12d_732838_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D0%B7%D0%B0%D0%BF%D1%83%D1%81%D0%BA-stable-diffusion-%D1%83-%D0%B2%D1%96%D1%80%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%96%D0%B9-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D1%96-%D0%BD%D0%B0-%D0%B2%D1%96%D0%B4%D0%B5%D0%BE%D0%BA%D0%B0%D1%80%D1%82%D1%96-amd-automatic1111--kvm--gpu-passthrough/","title":"Запуск Stable Diffusion у віртуальній машині на відеокарті AMD (AUTOMATIC1111 + KVM + GPU Passthrough)"},{"content":"Ознайомлення з KVM через IP KVM через IP (клавіатура, відео, миша через IP) — це технологія, яка забезпечує віддалений доступ і керування комп’ютером або сервером через мережеве з’єднання. Це дозволяє користувачам керувати сервером або ПК так, ніби вони фізично присутні біля машини, незалежно від їхнього розташування.\nПринцип роботи Апаратний пристрій: KVM через IP являя собою апаратний пристрій, встановлений на сервері або інтегрований у апаратне забезпечення сервера. Цей пристрій підключається до портів клавіатури, відео та миші сервера.\nМережеве підключення: потім пристрій KVM через IP підключається до мережі інтернет, що забезпечує віддалений доступ до сервера.\nПрограмне забезпечення для доступу: користувачі можуть отримати віддалений доступ до консолі сервера за допомогою спеціального програмного забезпечення, наданого виробником пристрою KVM через IP. Це програмне забезпечення дозволяє користувачам переглядати екран сервера, керувати введенням даних з клавіатури та миші та взаємодіяти з сервером так, ніби вони фізично присутні.\nФункції безпеки: рішення KVM через IP часто мають такі функції безпеки, як шифрування та автентифікація, щоб забезпечити безпечний віддалений доступ до сервера.\nПереваги KVM над програмним забезпеченням віддаленого робочого столу Доступ низького рівня: KVM через IP забезпечує доступ низького рівня до сервера, дозволяючи користувачам взаємодіяти з сервером або ПК на рівні BIOS та під час процесу завантаження. Цей рівень доступу зазвичай недоступний для програмних рішень для віддаленого робочого столу, які працюють у середовищі операційної системи.\nНезалежність від операційної системи: оскільки KVM через IP працює на апаратному рівні, такі апаратні засоби не залежить від операційної системи сервера. Це означає, що його можна використовувати для усунення несправностей і керування серверами та ПК, навіть якщо операційна система не відповідає або не працює.\nУправління поза діапазоном: KVM через IP забезпечує можливості керування поза діапазоном, дозволяючи адміністраторам отримувати віддалений доступ і керувати серверами, навіть якщо мережа або операційна система не працює. Це може бути вирішальним для завдань з усунення несправностей і обслуговування.\nПродуктивність: рішення KVM через IP часто забезпечують кращу продуктивність порівняно з програмними рішеннями для віддаленого робочого столу, особливо для завдань, які вимагають низької затримки та високої роздільної здатності.\nВстановлення програмного забезпечення не вимагається: оскільки KVM через IP є апаратним рішенням, воно не потребує встановлення програмного забезпечення на стороні сервера, що може спростити розгортання та обслуговування.\nОгляд апаратних рішень Промислові перемикачі KVM На ринку доступно багато пристроїв KMV через IP, але вони мають деякі недоліки, якщо вам потрібне доступне рішення для особистого використання, яке включає такі ключові моменти:\nВартість: промислові апаратні рішення KVM зазвичай передбачають вищі витрати порівняно з рішеннями з відкритим кодом, оскільки вони часто мають додаткові функції та послуги підтримки.\nПропрієтарне програмне забезпечення: більшість KVM-перемикачів, які виготовляються для виробничого використання в серверних кімнатах і центрах обробки даних критичної інфраструктури, постачаються в комплекті з програмним забезпеченням із закритим вихідним кодом, яке має власну ліцензію.\nPiKVM Найкращим рішенням для персональної домашньої серверної лабораторії або віддаленого керування ПК чи ноутбуком є PiKVM – недороге рішення IP-KVM з відкритим вихідним кодом на основі одноплатного ARM комп’ютера Raspberry Pi .\nПристрій PiKVM має багато корисних функцій для керування віддаленою машиною, наприклад:\nСимуляція дисків: це дозволяє прикріпити локальний файл *.iso до віддаленої машини, це дозволяє віддалено переінсталювати будь-яку ОС.\nІмітація підключення/відключення USB периферії.\nКонтроль живленням ATX.\nЯкщо ви хочете стати власником пристрою PiKVM, то для вас існує 2 варіанти:\nЗамовити готовий пристрій на офіційному сайті.\nПридбайте одну з підтримуваних плат Raspberry Pi, а також необхідні електронні компоненти та зберіть пристрій своїми руками.\nСтворення власного пристрою PiKVM v2 Я вирішив самостійно створити пристрій PiKVM v2, оскільки для моєї країни немає варіантів доставки готових пристроїв. Крім того, збірка своїми руками дає більше гнучкості: можена створити пристрій відповідно до необхідних функцій, при цьоми обирати будь-які компоненти за власним бажанням.\nВибір компонентів Після вивчення офіційної документації PiKVM стає очевидним, що найкращою версією для збірки є PiKVM v2. Для виготовлення свого пристрою я використовував такі апаратні компоненти:\n1 x Raspberry Pi 4 Model B з 2 Гб оперативної пам\u0026rsquo;яті. 1 x Блок живлення GAN 65W PD 1 x HDMI USB карта захоплення відео 1 x Kingston SD картка пам\u0026rsquo;яті на 32 Gb 10-го класу. 2 x USB-A до USB-C кабелі (для виготовлення спеціального кабелю живлення). 1 X HDMI кабель. 1 x 80мм вентилятор (для активного охолодження). Виготовлення спеціального кабелю живлення Щоб мати можливість керувати віддаленим комп’ютером через саморобний KVM пристрій, комп’ютер повинен розпізнавати наш пристрій як HID USB-пристрій, який сприйматиметься комп’ютером так само, як нібито це інша клавіатура чи миша (комп’ютерна клавіатура та миша також є HID-пристроями).\nАле плата Raspberry Pi 4 Model B має критичний недлоік – вона має лише один порт USB-C, який може працювати як пристрій HID, і цей порт також використовується для живлення пристрою. Щоб виправити таке функціональне обмеження, треба виготовити спеціальний кабель, що може одночасно працювати як USB-пристрій для цільового хоста та отримувати зовнішнє живлення від адаптера живлення.\nЩоб виготовити такий нестандартний кабель живлення, вам знадобляться 2 кабелі USB-A male до USB-C male. Я рекомендую вибирати якісні кабелі, тому що для живлення плати сила струму становить 3А. Процес виготовлення кабелю включає наступні етапи:\nВізьміть перший кабель і зріжте ізоляцію. Залиште дроти лінії передачі даних (зелений і білий) як є та відріжте дроти живлення +5В (червоний) і землю (чорний).\nВізьміть другий кабель і відріжте його повністю. Нам потрібна лише частина USB-A.\nПрипаяйте провід живлення +5В (червоний) другої частини кабелю USB-A, до проводу живлення +5В (червоний) частини кабелю USB-C.\nПрипаяйте разом усі 3 заземлюючі (чорні) дроти всіх частин кабелю.\nРетельно ізолюйте всі контакти.\nТаким чином, роз’єм USB-C слід під’єднати до плати Raspberry Pi, роз’єм USB-A другого кабелю (того, до якого підключено живлення) слід під’єднати до адаптера живлення, а роз’єм USB-A першого кабелю (того, з дроти даних) слід підключити до ПК, яким ви хочете керувати. Для кращого розуміння нижче наведена схема пайки кабелю.\nТакож я рекомендую це відео на YouTube від розробника PiKVM, яке пояснює повний процес виготовлення цього спеціального кабелю.\nОсь фото кабелю, що вийшов у мене. Я позначив усі сторони кабелю, щоб уникнути плутанини роз\u0026rsquo;ємів під час підключення обладнання. Чорний кабель USB-A повинен підключатися до адаптера живлення, білий кабель USB-A — до комп’ютера, а роз’єм USB-C — для плати Raspberry Pi.\nЗбірка пристрою в саморобному корпусі Компоненти, які я використовую для створення пристрою, включають зовнішню плату захоплення відеосигналу HDMI, яку слід підключити до конкретного USB-порту плати Raspberry Pi. Для моїх потреб пристрій має бути портативним. Враховуючи це, офіційний корпус для Raspberry Pi дуже підходить, до того ж він коштує занадто дорого, на мій погляд. Тож я вирішив повністю зібрати пристрій та всі електронні компоненти в одному корпусі для кращої портативності. Кожен раз, коли мені потрібно використовувати його з іншим ПК, мені просто потрібно підключити до нього кабелі HDMI та USB.\nТакож не секрет, що плати Rasperry Pi можуть перегріватися під час роботи в умовах екстремального навантаження на процесор або в умовах безперервної роботи 24/7. Беручи це до уваги, я вирішив сконструювати корпус таким чином, щоб усе обладнання охолоджувалося вентилятором 80мм.\nНа жаль, у мене немає 3D-принтера, щоб спроектувати та створити якісний корпус, що мав би вигляд як у промислового пристрою. Мій корпус повністю ручної роботи. Я використовував переважно деякі старі пластикові панелі, що залишилися в мене після ремонту.\nВентилятор можна підключити до відповідних контактів GPIO на платі. Для цього я використав контакт №2 для +5В (червоний дріт) і контакт №6 для мінусу (чорний дріт) живлення вентилятора.\nЯ використовував роз’єм що вже був у вентилятора, але мені довелося перепінувати контакти на цьому роз’ємі в правильному порядку.\nТакож я вирішив додатково винести порт RJ-45 Ethernet збоку, тому що при використання кабельного підключення до мережі інтернет якість потокового відео краща, а затримка менша на відміну від підключення черех Wi-Fi. Для цього я зробив спеціальний подовжувач кабелю та встановив порт біля порту HDMI.\nПрошивка PiKVM OS Для того, щоб Raspberry Pi міг діяти як апаратний KVM-пристрій, слід записати на SD-карту образ операційної системи з відкритим вихідним кодом PiKVM.\nПравильний образ PiKVM, який підходить для конкретної моделі Raspberry Pi, можна знайти на сторінці PiKVM Flashing OS. У моєму випадку я завантажив образ платформи DIY PiKVM V2, Raspberry Pi 4 що запрограмовано для використання з HDMI-USB картою захоплення. Образ повністю відповідає апаратному забезпеченню, яке я використовував (Raspblerry Pi 4 Model B і USB карта захоплення відео).\nЩоб записани образ ОС на SD-карту, існує програмне забезпечення RPI Imager. Оскільки я використовую Arch Linux, я встановив його з офіційного пакета rpi-imager:\nsudo pacman -S rpi-imager Потім слід підключити SD-карту до комп’ютера. Оскільки мій комп’ютер не має вбудованого кард-рідера, я використовую адаптер micro-SD до USB-A.\nЩоб записати образ на картку пам\u0026rsquo;яті, виконайте такі дії:\nВідкрийте RPI Imager. Натисніть \u0026ldquo;Choose device\u0026rdquo; та виберіть модель вашої плати Raspberry Pi. В моєму випадку слід обрати \u0026ldquo;Raspberry Pi 4\u0026rdquo;. Натисніть \u0026ldquo;Choose OS\u0026rdquo;, прокрутіть до самого низу та виберіть опцію \u0026ldquo;Use custom image\u0026rdquo;. Потім у файловому менеджері виберіть завантажений раніше образ PiKVM. Натисніть \u0026ldquo;Choose storage\u0026rdquo; та виберіть картку пам\u0026rsquo;яті. Будьте обережні, та обирайте правильний пристрій, тому що RPI Imager відформатує вибраний пристрій. Переконайтеся, що всі поля заповнено правильно та натисніть «Далі». Далі ви побачите модальне діалогове вікно із запитом, чи бажаєте ви налаштувати деякі параметри, натисніть «НІ». Наостанок підтвердьте процес спалаху пристрою та зачекайте, доки RPI Imager завершить спалах і перевірку зображення. Налаштування підключення до Wi-Fi (необов\u0026rsquo;язково) Як я вже зазначав раніше, завжди краще використовувати кабельне інтернет з’єднання Ethernet RJ-45, оскільки воно надійніше та забезпечує кращу продуктивність відеопотоку та меншу затримку. Однак, оскільки я хочу, щоб пристрій був портативним, і я міг взяти його з собою та підключити до іншого комп\u0026rsquo;ютера, де, можливо, не буде можливості кабельного з’єднання. Для цього я встановлюю облікові дані Wi-Fi мережі точки доступу свого телефону на Android, який я завжди маю при собі, тому, коли плата Raspberry Pi завантажується без підключеного кабелю Ethernet, вона використовуватиме свій вбудований адаптер Wi-Fi і підключитися до мого телефону Android.\nЩоб налаштувати Wi-Fi, виконайте такі дії:\nПідключіть SD-карту до комп\u0026rsquo;ютера.\nВи побачите, що SD-карта має більше одного розділу, вам потрібно змонтувати перший розділ, який називається \u0026ldquo;PIBOOT\u0026rdquo;.\nЗнайдіть файл pikvm.txt в кореневій папці розділу \u0026ldquo;PIBOOT\u0026rdquo;. Якщо файла не існує - створіть його вручну, якщо файл вже існує, не видаляйте з нього жодних конфігурацій, вам потрібно додати 2 параметри внизу файлу.\nДодайте 2 параметри в кінець файлу. Замініть облікові дані у прикладі на облікові дані вашої мережі Wi-Fi.\n1 2 WIFI_ESSID=\u0026#39;my_wifi_network\u0026#39; WIFI_PASSWD=\u0026#39;the_most_secure_password_ever\u0026#39; Збережіть файл. Потім безпечно відключіть розділ і вийміть SD-карту. Встановіть SD-карту на плату. Перше завантаження Це важливий крок, оскільки під час першого завантаження PiKVM OS ініціалізує необхідні налаштування та генерує унікальні SSH-ключі та сертифікати безпеки.\nДля процедури першого завантаження виконайте такі кроки:\nВстановіть SD-карту з прошитою ОС PiKVM на плату Raspberry Pi.\nПідключіть плату Raspbery Pi до роутера за допомогою кабелю Ethernet RJ-45. Якщо у вас немає можливості використовувати Ethernet під час першого завантаження, ви можете налаштувати облікові дані Wi-Fi (як показано в попередньому кроці), але перед завантаженням переконайтеся, що мережа Wi-Fi доступна.\nЗавантажте плату Raspberry Pi. Для цього підключіть джерело живлення 5В 3А до порту USB-C на платі.\nЗачекайте деякий час, поки ОС PiKVM завершить першу ініціалізацію. Цей процес може тривати до 10 хвилин. 🔴 ВАЖЛИВО: не від’єднуйте кабель живлення від плати Raspberry Pi, доки не завершиться перша ініціалізація завантаження.\nПісля завершення процесу першого завантаження пристрій PiKVM підключиться до мережі та отримає локальну IP-адресу в локальній мережі вашого маршрутизатора. Щоб визначити, яку IP-адресу отримав PiKVM, перейдіть на сторінку налаштувань маршрутизатора та знайдіть підключені пристрої. У моєму випадку плата отримала IP-адресу 192.168.0.222, тому я буду використовувати її в усіх наступних прикладах. У вашому випадку IP-адреса буде іншою.\nДалі вам потрібен комп’ютер або смартфон, який під’єднаний до тієї ж локальної мережі, що й пристрій PiKVM. Відкрийте веб-браузер і перейдіть до URL-адреси IP-адреси https://192.168.0.222. Облікові дані за замовчуванням: логін admin з паролем admin.\nЗмініть стандартні паролі, щоб захистити свій пристрій. Детальний опис того, як це зробити, є в докуменації PiKVM.\nОновлення програмного забезпечення PiKVM OS PiKVM OS — це операційна система з відкритим кодом на базі Arch Linux. Важливо регулярно оновлювати ОС PiKVM, щоб отримувати оновлення безпеки та нові функції. Як і оновлення будь якої системи, основаної на базі ядра Linux, процедура також виконується через термінал. Ви можете використовувати оболонку ssh або термінал вбудований в веб-інтерфейс PiKVM.\nЩоб оновити ОС, виконайте такі дії:\nВідкрийте термінал у веб-інтерфейсі PiKVM. В якості альтернативи можна використовувати ssh.\nОтримайте root-доступ, ввівши команду su - і пароль від користувачва root.\nВиконайте команду pikvm-update і дочекайтеся завершення процесу. Будь ласка, переконайтеся, що ваш пристрій PiKVM не буде від\u0026rsquo;єднано від живлення та підключення до мережі інтернет під час процесу оновлення.\nНалаштування Tailscale VPN (необов’язково) Можуть виникнути ситуації, коли я не можу отримати доступ до однієї локальної мережі з платою PiKVM, наприклад, коли я підключив PiKVM до домашнього сервера, і я фізично не вдома, і мені потрібен віддалений доступ до мого сервера.\nКрім того, враховуючи критерій щоб PiKVM був максимально портативним, я також хочу мати можливість позичити свій пристрій PiKVM комусь, щоб ця особа могла взяти його та підключити до свого ПК та локальної мережі, а я в свою чергу міг підключитися до цього ПК віддалено, та, наприклад, зміг допогти встановити операційну систему.\nTailscale VPN — це безкоштовний інструмент (для особистого користування), який можна використовувати як рішення для вище описаних випадків. Він дозволяє отримати доступ до PiKVM через мережу інтернет. Щоб налаштувати його, виконайте такі дії:\nВідкрийте термінал у веб-інтерфейсі PiKVM. В якості альтернативи можна використовувати ssh.\nВстановіть службу tailscale, ввівши цю послідовність команд в терміналі:\n1 2 3 4 5 su - rw pacman -S tailscale-pikvm systemctl enable --now tailscaled tailscale up Термінал покаже посилання, яке потрібно скопіювати та перейти у веб-браузері. Після переходу за посиланням увійдіть або зареєструйтеся в Tailscale VPN, тоді ваш пристрій PiKVM буде долучено до цього облікового запису.\nВстановіть клієнт Tailscale у систему, яку ви хочете використовувати (не на комп’ютер, яким хочете керувати через PiKVM), і підключіть його до VPN. Для цього дотримуйтесь інструкцій тут.\nПісля налаштування клієнта у вашій системі відвідайте сторінку адміністратора Tailscale. Якщо ви все зробили правильно, ви повинні побачити свій пристрій PiKVM і систему, що використовується для віддаленого підключення до PiKVM.\nНа знімку екрана вище я виділив приклад IP-адреси, яку слід використовувати в браузері для віддаленого підключення до PiKVM.\nПереконайтеся, що ви вимкнули термін дії ключа для пристрою PiKVM. Щоб зробити це, натисніть значок «три крапки» праворуч від пристрою PiKVM у списку та виберіть опцію «Вимкнути термін дії ключа». Після завершення налаштування під час кожного завантаження пристрою PiKVM він автоматично підключатиметься до мережі VPN, тому, якщо мені потрібен віддалений доступ до нього з будь-якого місця, я можу просто підключити свій ноутбук чи телефон, що маю з собою, до тієї ж мережі VPN та керувати своїм пристроєм PiKVM.\nІнструкція з використання пристрою PiKVM для керування ПК / ноутбуком / сервером Це інструкція стосується використання пристрою PiKVM як портативного. Для підключення вам необхідно мати: пристрій PiKVM, машину, якою ви хочете керувати, спеціальний кабель живлення та адаптер, кабель Ethernet RJ-45, кабель HDMI.\nВізьміть кабель Ethernet RJ-45 та підключіть його до пристрою PiKVM та до вашого роутера. Візьміть кабель HDMI та підключіть його до пристрою PiKVM та до машини, якою ви хочете керувати. Візьміть спеціальний кабель живлення та підключіть: USB-C роз\u0026rsquo;єм до пристрою PiKVM. USB-A роз\u0026rsquo;єм що позначено \u0026ldquo;PC/Laptop (комп\u0026rsquo;ютер)\u0026rdquo; до машини, якою ви хочете керувати. USB-A роз\u0026rsquo;єм що позначено \u0026ldquo;Power (живлення)\u0026rdquo; до адаптера живлення. Підключіть адаптер живлення до електричної розетки. Пристрій PiKVM має завантажитися та підключитися до мережі.\nЗапустіть машину, якою ви хочете керувати.\nПісля цього ви зможете підключитися до пристрою PiKVM.\nВисновки В результаті цього проекту було зібрано портативний пристрій KVM через IP, який має весь необхідний для моїх потреб функціонал:\nПристрій може використовувати як Ethernet, так і Wi-Fi з\u0026rsquo;єднання. Пристроєм можна повністю керувати віддалено за допомогою VPN. Пристрій зібрано в спеціальному унікальному корпусі ручної роботи, що використовує активне охолодження для запобігання перегріванню пристрою, тому його можна безпечно використовувати 24/7. ","date":"2024-03-29T00:00:00Z","image":"http://localhost:1313/post/assembling-a-pikvm-v2-device-for-remote-kvm-over-ip-control-of-a-computer-or-server/header_huaf7132429931ddcde60d8d9ee0a89d27_286083_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D0%B2%D0%B8%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F-%D0%BF%D1%80%D0%B8%D1%81%D1%82%D1%80%D0%BE%D1%8E-pikvm-v2-%D0%B4%D0%BB%D1%8F-%D0%B2%D1%96%D0%B4%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BA%D0%B5%D1%80%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-%D0%BA%D0%BE%D0%BC%D0%BF%D1%8E%D1%82%D0%B5%D1%80%D0%BE%D0%BC-%D0%B0%D0%B1%D0%BE-%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D0%BE%D0%BC-kvm-%D1%87%D0%B5%D1%80%D0%B5%D0%B7-ip/","title":"Виготовлення пристрою PiKVM v2 для віддаленого керування комп’ютером або сервером (KVM через IP)"},{"content":"Що таке Linux Zen Kernel? Ядро Linux Zen Kernel — це модифікована версія ядра Linux, яка зосереджена на забезпеченні покращеної продуктивності, швидкості реагування та гнучкості для користувачів настільних комп’ютерів і робочих станцій. Він розроблений і підтримується проектом Zen Kernel, метою якого є оптимізація ядра для настільних комп’ютерів.\nЯдро Zen містить різні виправлення та оптимізації, спрямовані на зменшення латентності, покращення реагування системи та підвищення загальної продуктивності системи. Ці оптимізації можуть включати налаштування планувальника (scheduler), покращення планувальника вводу-виводу (IO scheduler), покращення планування ЦП та інші налаштування, пов’язані з продуктивністю.\nКористувачі, які надають перевагу продуктивності та швидкодії робочого столу чи робочої станції, можуть вибрати використання ядра Linux Zen замість стандартного ядра Linux, яке надається їхнім дистрибутивом. Однак важливо зазначити, що Zen Kernel є модифікацією сторонніх розробників і може офіційно підтримуватися не всіма дистрибутивами Linux. Користувачі, які бажають випробувати Zen Kernel, повинні переглянути документацію та інструкції, надані проектом Zen Kernel або спільнотою свого конкретного дистрибутива.\nОсновні переваги Ключові функції та оптимізації, що містяться в ядрі Linux Zen, включають такі основні переваги:\nНабір патчів для зменшення затримки: ці патчі спрямовані на зменшення затримки ядра, покращення реагування, що особливо важливо для інтерактивного використання робочого столу, обробки звуку та ігор.\nПланувальник вводу-виводу BFQ: ядро Zen часто містить планувальник вводу-виводу BFQ (Budget Fair Queueing), який визначає пріоритетність запитів вводу-виводу на основі процесу, який їх генерує, з метою забезпечення більш плавної роботи системи, особливо під час багатозадачності або під час роботи. з інтерактивними додатками.\n— Додаткові планувальники ЦП: у деяких випадках ядро Zen включає альтернативні алгоритми планування ЦП або оптимізації для покращення продуктивності багатозадачності та швидкості реагування.\nПідтримка випередження та реального часу: ядро може включати виправлення для покращення можливостей випередження та реального часу, зменшення затримок та покращення реагування на чутливі до часу завдання. — Оптимізації за замовчуванням: деякі параметри ядра налаштовано за замовчуванням, щоб краще відповідати робочому навантаженню робочого столу та мультимедіа.\nСтабільність і надійність: наголошуючи на покращенні продуктивності, розробники ядра Zen зазвичай забезпечують підтримку стабільності та надійності, хоча користувачі завжди повинні знати, що будь-які модифікації ядра можуть становити ризик. Встановлення (Arch Linux) Ядро Linux Zen включено в менеджер пакетів Arch Linux pacman і може бути легко встановлено за допомогою pacman:\nsudo pacman -S linux-zen linux-zen-headers Після цього ядро фактично буде встановлено у вашій системі, але тепер настав час налаштувати завантажувач (bootloader) на завантаження з ядром Linux Zen Kernel замість стандартного. Це може залежати від вашого завантажувача, у моєму випадку я використовую systemd-boot.\nЗаписи завантаження знаходяться в каталозі /boot/loader/entries, тому перейдіть туди:\ncd /boot/loader/entries/ І виведіть в термінал всі ваші записи для завантаження:\nls -la У моєму випадку я маю лише один запис arch.conf:\n1 2 3 drwxr-xr-x 2 root root 4096 Feb 24 14:42 . drwxr-xr-x 3 root root 4096 Mar 25 20:15 .. -rwxr-xr-x 1 root root 208 Mar 18 18:31 arch.conf Я рекомендую залишити оригінальний запис завантаження (boot entry) та оригінальне ядро Linux для резервної копії, тож якщо нове ядро не завантажиться, ви завжди матимете можливість завантажитися зі стандартного ядра у завантажувачі.\nСтворіть дублікат початкового файлу запису завантаження:\nsudo cp arch.conf arch-zen.conf Потім відредагуйте файл arch-zen.conf за допомогою обраного вами текстового редактора, у моєму випадку я використовую nano таким чином:\nsudo nano arch-zen.conf Потім змініть конфігурацію та замініть 3 параметри (title, linux, initrd) відповідно до прикладу вище:\nРаніше (оригінальний файл arch.conf):\n1 2 3 title Arch Linux linux /vmlinuz-linux initrd /initramfs-linux.img Після (змінити у файлі arch-zen.conf):\n1 2 3 title Arch Linux Zen linux /vmlinuz-linux-zen initrd /initramfs-linux-zen.img Після збереження файлу перезавантажте систему та виберіть Arch Linux Zen під час завантаження.\nВисновки Підводячи підсумок, ядро Linux Zen створено для користувачів, які надають перевагу швидкості реагування робочого столу, мультимедійній продуктивності та іграм. Однак користувачі повинні ретельно оцінити, чи відповідають конкретні оптимізації та виправлення, надані ядром Zen, їхнім потребам і вподобанням, оскільки деякі функції можуть послабити продуктивність загального призначення або сумісність для спеціальних випадків використання.\n","date":"2024-03-25T00:00:00Z","image":"http://localhost:1313/post/install-linux-zen-kernel-on-arch-linux-to-improve-performance/header_hu4b29e357e57d8fe0ebc72c8e749e5da1_83937_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D0%B2%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F-%D0%BA%D0%B0%D1%81%D1%82%D0%BE%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE-%D1%8F%D0%B4%D1%80%D0%B0-linux-zen-%D0%BD%D0%B0-arch-linux-%D0%B4%D0%BB%D1%8F-%D0%BF%D0%BE%D0%BA%D1%80%D0%B0%D1%89%D0%B5%D0%BD%D0%BD%D1%8F-%D1%88%D0%B2%D0%B8%D0%B4%D0%BA%D0%BE%D0%B4%D1%96%D1%97-%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B8/","title":"Встановлення кастомного ядра Linux ZEN на Arch Linux для покращення швидкодії системи"},{"content":"Вступ Прокидання GPU в KVM відноситься до процесу безпосереднього призначення фізичного GPU (графічного пристрою) віртуальній машині, що працює на гіпервізорі KVM. Це дозволяє віртуальній машині мати виключний доступ до GPU, обійшовши практично віртуалізаційний шар гіпервізора.\nДля багатьох це може звучати складно, але з Linux та KVM це насправді легко, і налаштування включає наступні 5 кроків:\nПеревірка GPU. Перший крок - переконатися, що GPU, який ви хочете передати, сумісний з вашим обладнанням і підтримує необхідні функції для прохідного доступу. Це часто потребує підтримки VT-d (віртуалізаційна технологія Intel для прямого введення/виведення) або AMD-Vi (AMD віртуалізація I/O) на процесорі, а також IOMMU (одиниця управління пам\u0026rsquo;яттю введення/виведення) на материнській платі.\nНалаштування хоста. Вам потрібно налаштувати систему хоста для активації IOMMU, VT-d або AMD-Vi в налаштуваннях BIOS/UEFI, а також завантажити необхідні модулі ядра та драйвери.\nІзоляція GPU. GPU, призначений для прохідного доступу, потрібно ізолювати від операційної системи хоста таким чином, щоб його можна було виключно призначити для віртуальної машини. Це зазвичай робиться шляхом блокування завантаження драйвера GPU на хості.\nНалаштування віртуальної машини. У межах налаштування KVM ви налаштовуєте віртуальну машину для використання GPU, що прокидується. Це включає вказівку GPU як пристрій PCI для передачі до ВМ.\nВстановлення драйверів. Після передачі GPU віртуальній машині ви встановлюєте необхідні драйвери в гостьовій операційній системі так само, як і на фізичній машині.\nВимоги до обладнання Важливо відзначити, що для такого типу налаштувань необхідно, щоб ваше обладнання відповідало вимогам.\nЦП (процесор) Ваш процесор повинен підтримувати розширення апаратної віртуалізації, такі як Intel VT-x (Intel Virtualization Technology) або AMD-V (AMD Virtualization). Крім того, для пропускання GPU вам знадобиться підтримка розширень Intel VT-d (Intel Virtualization Technology for Directed I/O) або AMD-Vi (AMD Virtualization I/O), які дозволяють прямий доступ до пристроїв вводу-виводу з віртуальних машин.\nМатеринська плата Ваша материнська плата повинна мати IOMMU (Input-Output Memory Management Unit), яка підтримує ізоляцію та пропускання пристроїв PCIe. Більшість сучасних материнських плат мають цю функцію, але вам слід перевірити специфікації вашої материнської плати, щоб переконатися в сумісності.\nGPU (графічний процесор) Ваш графічний процесор повинен підтримувати UEFI. Ідеальним вибором буде GPU, який підтримує необхідні функції для пропускання, такі як GPU серії AMD Radeon Pro або Nvidia Quadro, оскільки в GPU для споживачів можуть бути обмеження або вимагати обхідних шляхів.\nНалаштування пропускання GPU Перегляньте ваше обладнання Першим кроком для налаштування є перегляд вашого обладнання. Якщо ви хочете досягти такого ж налаштування, як у моєму випадку, переконайтеся, що у вас є 2 відеокарти (або принаймні одна зовнішня відеокарта PCI).\nСпецифікації мого обладнання:\nМатеринська плата: MSI MPG z490 Gaming Edge WiFi ЦП: Intel Core i9-10850K GPU 1: AMD Radeon RX 6750XT (для HOST Linux) GPU 2: AMD Radeon RX 6600 (для GUEST Windows) Монітори: 2 x FullHD 1920x1080 @ 75 Гц Встановлення та налаштування KVM Цей посібник написаний з припущенням, що у вас вже працює система Linux з встановленим та налаштованим KVM (libvirt) та програмним забезпеченням для керування вашими віртуальними машинами (virt-manager, virt-viewer).\nЯкщо у вас ще не встановлено KVM, перегляньте мій інший посібник: Як встановити KVM на Arch Linux.\nЗміна налаштувань BIOS материнської плати Для того щоб KVM працював на вашій системі, технологія віртуалізації повинна бути включена. Вона може мати різні назви залежно від виробника материнської плати/процесора, але зазвичай це VT-D для Intel та AMD-Vi для AMD відповідно.\nЯкщо у вас є налаштування BIOS з інтегрованою графікою в процесорі, вам також потрібно буде змінити пріоритет ініціалізації графіки. Це потрібно для того, щоб запобігти ініціалізації зовнішнього GPU при старті BIOS POST, і делегувати відеосигнал інтегрованій графіці. У моєму випадку цей крок не потрібний, оскільки у мене є 2 зовнішні PCI GPU.\nУвімкнення IOMMU IOMMU - це загальна назва для Intel VT-d та AMD-Vi.\nДля включення IOMMU в системі Linux вам слід передати правильний параметр завантаження ядра. Додавання параметрів завантаження ядра може відрізнятися в залежності від того, який завантажувач ви використовуєте.\nЯкщо ви використовуєте:\nПроцесор Intel - додайте прапори: intel_iommu=on iommu=pt Процесор AMD - додайте прапори: iommu=pt У випадку процесорів AMD ядро визначає, чи має бути увімкнений IOMMU з BIOS, і iommu=pt запобігає обробці пристроїв, які не можуть бути пропущені через IOMMU.\nВаріант 1: GRUB Якщо ви використовуєте grub як свій завантажувач, ви можете змінити параметри ядра в файлі /etc/default/grub та додати прапори до параметрів GRUB_CMDLINE_LINUX, наприклад:\n1 2 3 ... GRUB_CMDLINE_LINUX=\u0026#34;quiet splash intel_iommu=on iommu=pt\u0026#34; ... Потім збережіть файл і перегенеруйте конфігурацію вашого GRUB за допомогою команди:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Опція 2: Завантаження через systemd Boot Якщо ви використовуєте завантажувач systemd boot, вам потрібно відредагувати файл вашого завантаження. У моєму випадку цей файл розташований за адресою /boot/loader/entries/arch.conf.\nПараметри ядра слід додати в кінець параметра options, наприклад:\n1 2 3 ... options rw quiet splash intel_iommu=on iommu=pt ... Після додавання правильних параметрів ядра до вашого завантажувача, перезавантажте комп\u0026rsquo;ютер.\nПеревірка групування IOMMU Група IOMMU (Input-Output Memory Management Unit) - це логічне об\u0026rsquo;єднання пристроїв, які контролюються тією ж самою IOMMU. Основна мета групи IOMMU полягає в тому, щоб сприяти ізоляції та управлінню пристроями в віртуалізованих середовищах, зокрема при використанні технологій пропускання GPU.\nВажливо, щоб у тій самій групі IOMMU були лише пристрої, пов\u0026rsquo;язані з GPU, який ви маєте намір пропустити через них. Оскільки, якщо ви маєте щось інше, воно також повинно бути передане в ВМ, інакше пропускання не працюватиме.\nВи можете скористатися наступним скриптом, щоб перевірити ваші групи iommu:\n1 2 3 4 5 6 7 8 #!/bin/bash shopt -s nullglob for g in $(find /sys/kernel/iommu_groups/* -maxdepth 0 -type d | sort -V); do echo \u0026#34;IOMMU Group ${g##*/}:\u0026#34; for d in $g/devices/*; do echo -e \u0026#34;\\t$(lspci -nns ${d##*/})\u0026#34; done; done; Вам потрібно зберегти вміст скрипта у файл (наприклад, iommu.sh) і зробити цей файл виконуваним (chmod +x iommu.sh), після чого ви можете просто запустити його за допомогою ./iommu.sh.\nУ моєму випадку групи IOMMU такі:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 IOMMU Group 0: 00:00.0 Host bridge [0600]: Intel Corporation Comet Lake-S 6c Host Bridge/DRAM Controller [8086:9b33] (rev 05) IOMMU Group 1: 00:01.0 PCI bridge [0604]: Intel Corporation 6th-10th Gen Core Processor PCIe Controller (x16) [8086:1901] (rev 05) 01:00.0 PCI bridge [0604]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 10 XL Upstream Port of PCI Express Switch [1002:1478] (rev c0) 02:00.0 PCI bridge [0604]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 10 XL Downstream Port of PCI Express Switch [1002:1479] 03:00.0 VGA compatible controller [0300]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 22 [Radeon RX 6700/6700 XT/6750 XT / 6800M/6850M XT] [1002:73df] (rev c0) 03:00.1 Audio device [0403]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 21/23 HDMI/DP Audio Controller [1002:ab28] ... IOMMU Group 18: 07:00.0 VGA compatible controller [0300]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 23 [Radeon RX 6600/6600 XT/6600M] [1002:73ff] (rev c7) IOMMU Group 19: 07:00.1 Audio device [0403]: Advanced Micro Devices, Inc. [AMD/ATI] Navi 21/23 HDMI/DP Audio Controller [1002:ab28] ... Переконайтеся, що GPU та пов\u0026rsquo;язані з ним пристрої не згруповані з іншими критичними системними пристроями (наприклад, контролерами USB, контролерами Ethernet), які ви не маєте наміру передавати у віртуальну машину. Важливо, щоб GPU був у власній ізольованій групі IOMMU для надійного пропускання.\nУ цьому випадку AMD RX 6600 GPU, який я хочу передати до ВМ, має 2 пристрої 07:00.0 і 07:00.1, кожен у окремій групі IOMMU 18 і 19, і жодні інші пристрої не знаходяться в групах 18 і 19. Це означає, що я можу пропускати його без проблем.\nЯкщо ми подивимося на пристрої для AMD RX 6750 XT, які є 03:00.0 і 03:00.1 у групі IOMMU 1, також є деякі пристрої PCI-мосту, які в теорії не заважатимуть пропусканню цього GPU, поки ви також передасте ці PCI-мости до ВМ. Справжньою проблемою було б, якщо, наприклад, група IOMMU 1 містила б інший PCI-пристрій (наприклад, мост USB або звукову карту).\nУ випадку, якщо у вас більше пристроїв, ніж вам потрібно в групі IOMMU з GPU, ви можете спробувати:\nЯкщо ваша материнська плата має багато слотів PCI Express, спробуйте встановити GPU в різні слоти PCI Express і подивіться, чи допоможе це. У випадку, якщо ви не можете знайти оптимальну групу IOMMU без зайвих пристроїв, ви можете патчити свій ядро Linux з патчем ACS Override (але це виходить за рамки цієї статті). Ізолюйте ваш GPU Ізоляція GPU - це процес забезпечення того, що GPU доступний виключно для використання конкретною віртуальною машиною, зазвичай шляхом прив\u0026rsquo;язки його до драйвера VFIO (Virtual Function I/O). Цей процес включає кілька кроків для запобігання використання GPU операційною системою хоста або іншими віртуальними машинами:\nВідв\u0026rsquo;язка від драйвера хоста. Спочатку GPU зазвичай прив\u0026rsquo;язаний до драйвера, який використовується операційною системою хоста для звичайних графічних операцій. Для ізоляції GPU цю прив\u0026rsquo;язку потрібно скасувати, щоб GPU міг бути вибраний драйвером VFIO. Цей крок фактично відокремлює GPU від операційної системи хоста.\nПрив\u0026rsquo;язка до драйвера VFIO. Після відв\u0026rsquo;язки від драйвера хоста GPU прив\u0026rsquo;язується до драйвера VFIO, що дозволяє його передавати до віртуальної машини. Драйвер VFIO надає необхідну функціональність для прямого призначення пристроїв (DDA) в віртуалізованих середовищах, забезпечуючи доступність GPU для віртуальної машини.\nІзоляція означає, що після того, як ви завантажите вашу хостову операційну систему Linux, ви не зможете використовувати ізольований GPU (який прив\u0026rsquo;язаний до драйвера vfio), ви можете використовувати його лише для передачі в ВМ.\nДля ізоляції GPU вам потрібно знати ідентифікатори пристроїв вашої відеокарти та аудіовиходу PCI. Ви можете використовувати скрипт iommu.sh з попереднього кроку, щоб отримати цю інформацію. У моєму випадку ідентифікатори пристроїв - 1002:73df і 1002:ab28.\nРаннє завантаження VFIO Щоб завантажити vfio ранніше та прив\u0026rsquo;язати необхідний GPU до vfio, створіть конфігураційний файл за адресою /etc/modprobe.d/vfio.conf, який у моєму випадку виглядає наступним чином:\n1 2 softdep amdgpu pre: vfio-pci options vfio-pci ids=1002:73ff,1002:ab28 disable_vga=1 kvm.ignore_msrs=1 Тут рядок softdep amdgpu pre: vfio-pci дозволяє примусово завантажити драйвер vfio-pci перед драйвером amdgpu. Мені це потрібно через те, що у мене є 2 зовнішні PCI GPU від одного виробника, і це дозволяє прив\u0026rsquo;язати GPU RX 6600 до драйвера vfio-pci, а потім прив\u0026rsquo;язати RX 6750 XT до драйвера amdgpu.\nУ вашому випадку, якщо у вас є GPU NVidia, то vfio-pci повинен бути завантажений перед драйвером nvidia (пропрітарним) або перед драйвером nouveau (вільним).\nНалаштування initramfs У моєму випадку я використовую mkinitcpio як збирач initramfs. Для налаштування mkinitcpio відредагуйте файл /etc/mkinitcpio.conf.\nДодайте необхідні модулі до масиву MODULES:\n1 2 3 ... MODULES=(vfio_pci vfio vfio_iommu_type1) ... Потім переконайтеся, що у вас визначений хук modconf у масиві HOOKS:\n1 2 3 ... HOOKS=(... modconf ...) ... Збережіть файл, а потім виконайте команду для регенерації initramfs:\nsudo mkinitcpio -P Після цього потрібно перезавантажити комп\u0026rsquo;ютер, щоб зміни вступили в силу.\nНалаштування нової віртуальної машини та установка Windows 10/11 Тепер час налаштувати нову віртуальну машину та встановити нову операційну систему Windows. Я рекомендую налаштовувати та встановлювати Windows без будь-яких переданих PCI-пристроїв, і додати їх до віртуальної машини пізніше після завершення встановлення.\nВсе налаштування легше виконувати за допомогою графічного додатка virt-manager.\nВідкрийте додаток virt-manager.\nНатисніть \u0026ldquo;Нова віртуальна машина\u0026rdquo;.\nВиберіть локальний носій для встановлення. Зазвичай це файл образу iso Windows 10/11, який можна завантажити з веб-сайту Microsoft.\nПерейдіть до вашого файлу iso Windows 10/11. Рекомендується розташувати ваш iso десь у вашій домашній теки користувача, щоб уникнути проблем з правами доступу до файлів. Також важливо переконатися, що операційна система ідентифікована як \u0026ldquo;Windows 10\u0026rdquo; або \u0026ldquo;Windows 11\u0026rdquo; у нижньому полі. Виділіть CPU та пам\u0026rsquo;ять. Переконайтеся, що зарезервовано принаймні 2 ядра CPU та деяку кількість оперативної пам\u0026rsquo;яті для вашої системи хоста Linux, щоб вона могла керувати мережею та іншими процесами. У моєму випадку я виділив 2 ядра CPU та 8 Гб оперативної пам\u0026rsquo;яті для ВМ, ви можете виділити більше, якщо потрібно. Увімкніть зберігання для цієї віртуальної машини та створіть образ диску. Я рекомендую виділити принаймні 50 Гб для віртуальної машини Windows. Потім НЕ НАТИСКАЙТЕ FINISH, і виконайте наступне:\nПереконайтеся, що увімкнено \u0026ldquo;Customize Configuration before install\u0026rdquo;. Дайте вашій ВМ назву. У виборі мережі оберіть \u0026ldquo;Пристрій хоста [ваш ID пристрою] -\u0026gt; Source Mode -\u0026gt; Bridge або NAT\u0026rdquo;. Тепер ви можете натиснути \u0026ldquo;Finish\u0026rdquo;. Переконайтеся, що в «Огляді» вибрано чіпсет Q35 і мікропрограму UEFI. GPU Passthrough не працюватиме в мікропрограмі BIOS, для цього потрібно використовувати UEFI. Потім натисніть \u0026ldquo;Begin installation\u0026rdquo; та встановіть Windows, як зазвичай. Після встановлення системи перейдіть до наступного кроку.\nНалаштування певних параметрів ВМ Є необхідність додати деякі параметри, що дозволяють приховати той факт, що ви використовуєте віртуальну машину від програми встановлення драйверів GPU.\nДля редагування налаштувань ВМ переконайтеся, що ваша ВМ не запущена, і введіть цю команду в термінал:\nsudo virsh edit win10 де ви повинні замінити win10 на ім\u0026rsquo;я вашої ВМ.\nПотім виконайте наступні зміни в файлі XML в редакторі:\nДодайте \u0026lt;vendor_id state='on' value='randomid'/\u0026gt; до розділу \u0026lt;hyperv\u0026gt;. Додайте \u0026lt;kvm\u0026gt;\u0026lt;hidden state='on'/\u0026gt;\u0026lt;/kvm\u0026gt; до розділу \u0026lt;features\u0026gt;. В результаті структура повинна виглядати так:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ... \u0026lt;features\u0026gt; ... \u0026lt;hyperv\u0026gt; ... \u0026lt;vendor_id state=\u0026#39;on\u0026#39; value=\u0026#39;randomid\u0026#39;/\u0026gt; ... \u0026lt;/hyperv\u0026gt; \u0026lt;kvm\u0026gt; \u0026lt;hidden state=\u0026#39;on\u0026#39;/\u0026gt; \u0026lt;/kvm\u0026gt; ... \u0026lt;/features\u0026gt; ... Прокидання GPU до ВМ У програмі virt-manager відкрийте налаштування вашої ВМ та перейдіть до відповідних налаштувань, де потрібно додати 2 PCI-пристрої хоста, пов\u0026rsquo;язані з GPU, який ви маєте намір пропустити.\nНатисніть \u0026ldquo;Додати пристрої PCI\u0026rdquo;.\nНатисніть \u0026ldquo;Додати обладнання\u0026rdquo;.\nВиберіть PCI-пристрій хоста\nПрокрутіть вниз, поки не знайдете GPU, який ви хочете пропустити. Ідентифікатори повинні відповідати виводам з попереднього етапу. Наприклад, у моєму випадку:\n0000:07:00:0 Advanced Micro Devices, Inc. [AMD/ATI] Navi 23 [Radeon RX 6600/6600 XT/6600M] 0000:07:00:1 Advanced Micro Devices, Inc. [AMD/ATI] Navi 21/23 HDMI/DP Audio Controller [1002:ab28] Вам потрібно це зробити двічі для відеопристрою та аудіопристрою GPU відповідно.\nПотім, якщо у вас є другий монітор, спробуйте підключити його до відеовиходу GPU, який ви пропустили до ВМ, та завантажте ВМ. Якщо все налаштовано правильно, ви повинні побачити відеовихід ВМ на окремому моніторі.\nВстановлення драйверів GPU Після успішного завантаження вашої Windows ВМ з зовнішнім GPU, час завантажити та встановити останні версії драйверів від виробника вашого GPU.\nОфіційні драйвери для GPU Nvidia Офіційні драйвери для GPU AMD Висновок Налаштована віртуальна машина Windows з пропусканням GPU може обробляти певні графічні програми (наприклад, геймінг або відеомонтаж) з майже нативною продуктивністю, що дозволяє використовувати вашу основну систему Linux та гостьову систему Windows одночасно.\nПереваги пропускання GPU в KVM включають:\nПокращена продуктивність: Шляхом безпосереднього доступу до фізичного GPU віртуальна машина може досягти майже нативної продуктивності для графічно інтенсивних завдань, таких як геймінг, відеомонтаж та 3D-моделювання.\nЗменшення накладних витрат: Оскільки віртуальна машина обходить віртуалізаційний шар гіпервізора для операцій з GPU, накладні витрати менше порівняно з традиційними техніками віртуалізації GPU, такими як емуляція GPU або віртуальні рішення GPU (vGPU).\nПідтримка завдань з апаратним прискоренням GPU: Пропускання GPU дозволяє віртуальним машинам використовувати апаратне прискорення для завдань, які покладаються на обробку GPU, що призводить до швидшого виконання та покращеної ефективності.\nСумісність з програмним забезпеченням, яке вимагає GPU: Деякі програми та робочі процеси вимагають прямого доступу до фізичного GPU, що можливо не здійснюється за допомогою віртуальних рішень GPU. Пропускання GPU дозволяє такому програмному забезпеченню працювати безперешкодно в віртуалізованому середовищі.\nГеймінг: Гравці можуть скористатися пропусканням GPU, запускаючи ігри в межах віртуальної машини з мінімальним зниженням продуктивності, що дозволяє використовувати апаратно-прискорену графіку без подвійного завантаження або виділення окремої фізичної машини для геймінгу.\n","date":"2024-03-18T00:00:00Z","image":"http://localhost:1313/post/gpu-pci-passthrough-to-windows-kvm-on-arch-linux/header_hued49b8fc40a4ce925bd267fd9ac65523_97296_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"http://localhost:1313/uk/post/%D0%BF%D1%80%D0%BE%D0%BA%D0%B8%D0%B4%D0%B0%D0%BD%D0%BD%D1%8F-%D0%B2%D1%96%D0%B4%D0%B5%D0%BE%D0%BA%D0%B0%D1%80%D1%82%D0%B8-pci-%D0%B4%D0%BE-windows-kvm-%D0%BD%D0%B0-arch-linux/","title":"Прокидання відеокарти PCI до Windows KVM на Arch Linux"},{"content":"Вступ KVM, що означає Kernel-based Virtual Machine (віртуальна машина на базі ядра), є рішенням для віртуалізації в операційних системах Linux. Воно дозволяє запускати кілька віртуальних машин (ВМ) на одній фізичній машині за допомогою вбудованих у сучасні процесори функцій віртуалізації апаратного забезпечення.\nОсь розбір того, що пропонує KVM:\nГіпервізор: KVM діє як гіпервізор, що є частиною програмного забезпечення, яке створює та запускає віртуальні машини. Воно використовує розширення віртуалізації, які присутні в сучасних процесорах (такі як Intel VT-x або AMD-V), для забезпечення апаратно-допомаганої віртуалізації.\nІнтеграція з ядром: KVM інтегрований у ядро Linux, що означає, що воно використовує функціональність ядра та користується постійними поліпшеннями ядра. Ця інтеграція забезпечує кращу продуктивність та стабільність для віртуалізованих середовищ.\nПовна віртуалізація: KVM підтримує повну віртуалізацію, що дозволяє гостьовим операційним системам працювати без змін. Це означає, що ви можете запускати різноманітні операційні системи, включаючи Linux, Windows та інші, як віртуальні машини на хості з підтримкою KVM.\nПродуктивність: KVM відомий своєю високою продуктивністю, завдяки підтримці апаратно-допомаганої віртуалізації та тісної інтеграції з ядром Linux. Це дозволяє ефективне використання ресурсів та мінімальний накладення при запуску віртуалізованих завдань.\nІнструменти управління: KVM можна керувати за допомогою різних інструментів, включаючи утиліти командного рядка, такі як virsh, та графічні інтерфейси, такі як Virt-Manager. Ці інструменти надають адміністраторам можливість створювати, налаштовувати та управляти віртуальними машинами на хостах з KVM.\nЗагалом, KVM є потужним та універсальним рішенням для віртуалізації в системах на базі Linux, пропонуючи продуктивність, гнучкість та зручність управління для віртуалізованих середовищ.\nВстановлення Перевірка підтримки віртуалізації Перш ніж встановлювати KVM, переконайтеся, що ваш процесор підтримує віртуалізацію та що вона увімкнена у налаштуваннях BIOS. Більшість сучасних процесорів підтримують віртуалізацію, але краще перевірити ще раз.\nДля отримання докладної інформації про перевірку вашого обладнання, будь ласка, зверніться до Arch Wiki - Перевірка підтримки KVM.\nВстановлення пакетів Відкрийте термінал та встановіть необхідні пакети. Це включає утиліту образів диска QEMU qemu, модуль ядра KVM kvm та API та інструмент управління віртуалізацією libvirt libvirt.\nsudo pacman -S virt-manager virt-viewer qemu dnsmasq bridge-utils Налаштування Служби libvirt Libvirt - це набір інструментів для взаємодії з можливостями віртуалізації ядра Linux. Увімкніть службу libvirt для управління віртуальними машинами.\nsudo systemctl enable --now libvirtd.service Увімкніть автозапуск для типової віртуальної мережі NAT для ваших віртуальних машин:\nsudo virsh net-start default sudo virsh net-autostart default Потім відредагуйте конфігурацію libvirt у файлі /etc/libvirt/libvirtd.conf та встановіть параметри:\n1 2 unix_sock_group = \u0026#34;libvirt\u0026#34; unix_sock_rw_perms = \u0026#34;0770\u0026#34; Додайте свого поточного користувача до групи libvirt:\nsudo usermod -a -G libvirt $(whoami) newgrp libvirt Наостанок, перезапустіть демона libvirt, щоб застосувати зміни:\nsudo systemctl restart libvirtd.service Після цього ви повинні мати змогу запустити virt-manager та використовувати віртуалізацію KVM, але якщо ви побачите деякі помилки, спробуйте перезавантажити вашу машину; якщо це не допоможе, перегляньте журнали та конфігурацію вашого демона libvirt.\nУвімкніть вкладену віртуалізацію (необов\u0026rsquo;язково) Вкладена віртуалізація дозволяє запускати існуючі віртуальні машини на сторонніх гіпервізорах та на інших хмарних сервісах без будь-яких змін у початкових віртуальних машинах або їхніх мережах.\nЩоб увімкнути її (тимчасово), скористайтеся наступними командами терміналу:\nsudo modprobe -r kvm_intel sudo modprobe kvm_intel nested=1 Потім, щоб перевірити, що вона увімкнена, перевірте результат команди:\ncat /sys/module/kvm_intel/parameters/nested вона повинна надрукувати Y, якщо вкладена віртуалізація увімкнена.\nЩоб зробити це зміну постійною при завантаженні вашої машини, скористайтеся командою:\necho \u0026#34;options kvm-intel nested=1\u0026#34; | sudo tee /etc/modprobe.d/kvm-intel.conf Посилання Arch Wiki - KVM. Wikipedia - KVM. Вихідний код Kernel Virtual Machine. ","date":"2024-03-15T00:00:00Z","image":"http://localhost:1313/post/how-to-install-kvm-on-arch-linux/header_hu9582e9719e96abf49c172162d020cea7_78147_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D0%B2%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F-%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B8-%D0%B2%D1%96%D1%80%D1%82%D1%83%D0%B0%D0%BB%D1%96%D0%B7%D0%B0%D1%86%D1%96%D1%97-kvm-%D0%BD%D0%B0-arch-linux/","title":"Встановлення системи віртуалізації KVM на Arch Linux"},{"content":"Введення Аутентифікація на основі ключа SSH — це метод безпечного входу у віддалену систему або сервер за допомогою криптографічних ключів замість паролів. Він працює на основі криптографії з відкритим ключем, де генерується пара ключів — відкритий і закритий ключ. Відкритий ключ зберігається на сервері, а закритий ключ надійно зберігається на стороні клієнта.\nЯк це працює? Генерація ключів: користувач генерує пару криптографічних ключів — відкритий і закритий ключ. Приватний ключ надійно зберігається на комп’ютері користувача, а відкритий ключ – на сервері.\nКонфігурація сервера: відкритий ключ додається до списку авторизованих ключів сервера. Це означає, що сервер розпізнає відповідний приватний ключ, коли він буде представлений під час спроб входу.\nСпроба входу: коли користувач намагається увійти на сервер, клієнтське програмне забезпечення представляє закритий ключ. Сервер перевіряє, чи цей закритий ключ відповідає будь-якому з відкритих ключів, які він записав для авторизованих користувачів.\nАвторизація: якщо сервер знаходить збіг, він дозволяє користувачеві увійти без необхідності вводити пароль.\nЧому використання ключів безпечніше? Авторизація на основі ключа вважається більш безпечною, ніж авторизація на основі пароля з кількох причин:\nСтійкість до bruteforce атак: паролі можна вгадати або зламати за допомогою bruteforce. Однак за допомогою автентифікації на основі ключа зловмиснику потрібно буде володіти приватним ключем, який в ідеалі повинен надійно зберігатися та не бути легкодоступним.\nНемає передачі паролів: під час авторизації на основі пароля пароль передається через мережу, яка потенційно може бути перехоплена зловмисниками. Завдяки авторизації на основі ключа закритий ключ ніколи не залишає клієнтську машину, тому немає ризику перехоплення.\nНадійніше шифрування: ключі SSH використовують надійні криптографічні алгоритми для авторизації, що робить їх стійкими до різних типів атак.\nНе потрібно покладатися на паролі, створені людиною: паролі, створені людиною, можуть бути слабкими та схильними до зламу. З іншого боку, ключі генеруються випадковим чином і зазвичай набагато довші, тому їх важче вгадати.\nЗагалом авторизація на основі ключа SSH забезпечує вищий рівень безпеки та рекомендована для віддаленого доступу до серверів і систем, особливо в середовищах, де безпека має першорядне значення.\nПриклад з налаштування Далі поговоримо про те, як реалізувати авторизацію на основі ключа RSA для доступу до віддаленого сервера через протокол SSH. Цей посібник припускає, що у вас є локальні та віддалені (серверні) системи Linux і ви вже маєте доступ до свого сервера через протокол ssh на основі пароля.\nГенерація нового ключа 🟢 Порада щодо безпеки: якщо у вас є кілька серверів, до яких ви хочете отримати доступ через SSH на основі ключа, наполегливо рекомендуємо створити окремий ключ ssh для кожного сервера.\nУсі ключі ssh зберігаються в каталозі .ssh, який розташований у вашому домашньому каталозі користувача, тому нам потрібно змінити робочий каталог у терміналі:\ncd ~/.ssh У моєму випадку не було каталогу .ssh, тому я створив його вручну:\nmkdir ~/.ssh Потім, щоб створити новий ключ:\nssh-keygen -t rsa -b 4096 Параметри в команді генерації вище означають:\n-t rsa: вказує тип ключа для створення. У цьому випадку це означає, що слід використовувати алгоритм RSA. RSA (Rivest-Shamir-Adleman) — це широко використовувана криптосистема з відкритим ключем для безпечної передачі даних.\nb 4096: визначає кількість бітів у ключі. У цьому випадку він встановлює розмір ключа 4096 біт. Більші розміри ключів зазвичай забезпечують сильніший захист, але також можуть вимагати більше обчислювальних ресурсів для шифрування та дешифрування.\nМайстер створення ключів запитає про деякі параметри:\nEnter a file in which save a key (Введіть файл, в якому буде збережено ключ). Якщо у вас є кілька ключів для кількох серверів, рекомендується назвати ваші ключові файли так, щоб пізніше було зрозуміло, який ключ використовується для доступу до певного сервера.\nEnter key passphraze (Введіть пароль ключа) - двічі. Щоб фактично розблокувати ключ ssh, вам потрібно вказати надійний пароль. Це означає, що якщо ваш ключ буде вкрадено або зламано, він усе ще буде захищений паролем.\n🟢 Порада щодо безпеки: рекомендується мати різні паролі для ключа ssh і для віддаленого користувача Unix.\nНарешті, після створення ключа ви побачите такий результат у терміналі:\nПередача ключа на віддалений сервер Ви можете скопіювати відкритий ключ ssh на свій сервер багатьма способами, але найбезпечнішим способом є використання SCP (захищеної копії).\n🟡 Примітка: Команди scp і ssh вимагають введення пароля віддаленого користувача (user).\nЩоб скопіювати відкритий ключ, використовуйте таку команду, але не забудьте замінити параметри на ваші фактичні:\nscp dc1srv1.pub user@192.168.0.2: Параметри команди scp означають:\ndc1srv1.pub — це файл відкритого ключа, створений на попередньому кроці. user - ім\u0026rsquo;я користувача на віддаленій машині. 192.168.0.2 - IP або домен віддаленої машини. : - шлях, куди скопіювати файл dc1srv1.pub (у цьому випадку домашній каталог віддаленого користувача user). Дозвіл на використання нового ключа Для цього нам потрібно підключитися до серверної оболонки через протокол SSH, в іншому терміналі підключитися до віддаленої оболонки:\nssh user@192.168.0.2 Потім перевірте, чи є у вас каталог .ssh у домашній папці віддаленого користувача user, якщо його немає, створіть його:\nmkdir ~/.ssh Створіть файл authorized_keys в каталозі .ssh:\ntouch ~/.ssh/authorized_keys Скопіюйте вміст відкритого ключа у файл authorized_keys:\ncat ~/dc1srv1.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys Після цього переданий на попередньому кроці файл відкритого ключа більше не потрібен, тому його можна видалити:\nrm ~/dc1srv1.pub Зміна конфігурації SSH Щоб змінити конфігурацію ssh, відредагуйте файл /etc/ssh/sshd_config:\nsudo nano /etc/ssh/sshd_config У цьому файлі ви повинні знайти деякі параметри та явно задати їхні значення:\n1 2 3 4 5 6 7 8 9 10 11 12 ... # Заборонити авторизацію від root PermitRootLogin no # Дозволити авторизацію ключами PubkeyAuthentication yes # Заборонити challenge response ChallengeResponseAuthentication no # Увімкнути PAM UsePAM yes # Заборонити авторизацію на базі пароля PasswordAuthentication no ... Після збереження файлу перезапустіть службу sshd:\nsudo systemctl restart sshd 🔴 ВАЖЛИВО: Після перезапуску sshd нова конфігурація набуде чинності. Рекомендовано НЕ ЗАКРИВАТИ ваш поточний відкритий сеанс ssh і зберігати його, доки ви не перевірите та не переконаєтеся, що ваш новий ключ ssh працює в ІНШОМУ вікні терміналу. У цьому випадку, якщо щось піде не так, ви все одно можете повернути зміни до файлу ssh_config і перезапустити демон sshd, щоб застосувати попередню конфігурацію.\nПеревірка SSH авторизації Переконайтеся що авторизація через пароль НЕ працює По-перше, давайте перевіримо, що ми не можемо підключитися як root і як загальний користувач, тому для команди:\nssh root@192.168.0.2 або:\nssh user@192.168.0.2 Ви повинні отримати повідомлення про помилку Permission denied (publickey).\nПереконайтеся що авторизація через RSA ключ працює Команда ssh для підключення до віддаленого сервера буде дещо іншою, оскільки вам слід вказати ключ ssh, який потрібно використовувати для автентифікації:\nssh -i ~/.ssh/dc1srv1 user@192.168.0.2 Після введення цієї команди вам буде запропоновано ввести пароль, який використовувався під час генерації ключа ssh.\nВисновки Після завершення нашалтування описаного в прикладі, ваш сервер використовує автентифікацію SSH на основі безпечного ключа. Майте на увазі, що вам потрібно створити резервну копію ваших ключів ssh, тому що, якщо ви втратите ключ ssh, ви не зможете підключитися до віддаленої машини через ssh (у цьому випадку лише фізичний доступ до віддаленої машини може допомогти скинути ключ, або якщо ви використовуєте VPS/хостинг-провайдера, деякі веб-панелі адміністратора дозволяють скинути нашалтування ssh).\n","date":"2024-03-10T00:00:00Z","image":"http://localhost:1313/post/configure-ssh-authorization-based-on-rsa-key/header_hu7e01c4855c80de0ee2ab35b4b9e2ae18_52924_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D0%BD%D0%B0%D0%BB%D0%B0%D1%88%D1%82%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-ssh-%D0%B0%D0%B2%D1%82%D0%BE%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D1%96%D1%97-%D0%BD%D0%B0-%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D1%96-rsa-%D0%BA%D0%BB%D1%8E%D1%87%D0%B0/","title":"Налаштування SSH авторизації на основі RSA ключа"},{"content":"Вступ Це мій власний мануал із встановлення Arch Linux на машину з UEFI, зашифрованим LVM і окремим розділом /home.\nКроки Спочатку вам потрібно створити та запустити інсталяитор на вашому ПК, у результаті ви завантажитесь у звичайну консоль.\nЗбільшити розмір шрифту Оскільки більшість сучасних ноутбуків/ПК мають дисплеї з великою роздільною здатністю, я рекомендую збільшити розмір шрифту:\nsetfont ter-132b Налаштуйте підключення до Інтернету У цьому прикладі використовується ПК із модемом Wi-Fi, тому я буду використовувати iwd для налаштування підключення до Інтернету.\nЗапуск iwd:\niwctl Переглянути список адаптерів Wi-Fi:\ndevice list Зазвичай ви маєте бачити один пристрій Wi-Fi на виході, у моєму випадку це wlan0\nПотім, якщо ви знаєте SSID станції та пароль, просто підключіться до станції та не забудьте замінити {SSID} своїм фактичним значенням:\nstation wlan0 connect {SSID} Потім вийдіть із iwctl, ввівши exit, виконайте ping 8.8.8.8, щоб переконатися, що ви підключені до Інтернету.\nСинхронізувати системний годинник timedatectl set-ntp true Розбийте диск на розділи У моєму випадку я хочу мати окремі розділи root, /boot і /home, крім того, / і /home мають бути зашифровані LVM і перебувати в одній групі томів.\nВизначте свій диск По-перше, нам потрібно знати, який диск слід використовувати, щоб переглянути дискові пристрої:\nfdisk -l У моєму випадку це NVMe SSD-накопичувач /dev/nvme0n1.\nРозмітка розділів Далі скористайтеся gdisk /dev/nvme0n1, щоб створити розділи з таким макетом:\n/dev/nvme0n1p1 - принаймні 512M - тип EF00 - Системний розділ EFI /dev/nvme0n1p2 - решта диска - тип 8309 - LUKS Відформатуйте фізичні розділи Розділ EFI mkfs.vfat -F 32 /dev/nvme0n1p1 Зашифрований розділ LUKS cryptsetup luksFormat /dev/nvme0n1p2 Створення групи томів і логічних томів Спочатку відкрийте зашифрований контейнер:\ncryptsetup luksOpen /dev/nvme0n1p2 luks У результаті зашифрований розділ монтується в /dev/mapper/luks.\nДалі розглядайте /dev/mapper/luks як LVM PV і створіть свої томи. У моєму випадку такі:\nГрупа томів vg0 Логічний том lv_root - Ймовірно, принаймні 20G, я використовую 75G Логічний том lv_swap - Необов\u0026rsquo;язковий, можливо, небажаний, якщо у вас є SSD Логічний том lv_home - Решта простору Команди для досягнення цього:\n1 2 3 4 5 pvcreate /dev/mapper/luks vgcreate vg0 /dev/mapper/luks lvcreate -L 75G -n lv_root vg0 lvcreate -L 16G -n lv_swap vg0 lvcreate -l100%FREE -n lv_home vg0 Відформатуйте логічні томи Я буду використовувати файлові системи ext4 для свого налаштування, тут ви можете використовувати щось інше (наприклад, btrfs).\nЩоб відформатувати кореневий і домашній розділи в ext4:\n1 2 mkfs.ext4 /dev/vg0/lv_root mkfs.ext4 /dev/vg0/lv_home Щоб відформатувати розділ підкачки та ввімкнути його:\n1 2 mkswap /dev/vg0/lv_swap swapon /dev/vg0/lv_swap Монтування розділів Цей крок потрібен для монтування створених розділів і інсталяції туди системи Arch Linux. Усі файлові системи мають бути змонтовані з урахуванням /mnt як кореневої файлової системи для майбутньої встановленої системи.\n1 2 3 mount --mkdir /dev/vg0/lv_root /mnt mount --mkdir /dev/vg0/lv_home /mnt/home mount --mkdir /dev/nvme0n1p1 /mnt/boot Встановлення базової системи pacstrap -K /mnt base base-devel linux linux-firmware linux-headers Створення fstab genfstab -U /mnt \u0026gt;\u0026gt; /mnt/etc/fstab Chroot у систему arch-chroot /mnt Створити локалізацію Розкоментуйте en_US.UTF-8 UTF-8 та інші необхідні локалі у файлі /etc/locale.gen.\nПотім згенеруйте локалі:\nlocale-gen Щоб установити локаль системи:\necho \u0026#34;LANG=en_US.UTF-8\u0026#34; \u0026gt; /etc/locale.conf Налаштуйте ім\u0026rsquo;я хоста Насправді це аналог назви комп’ютера в Windows, у моєму випадку я назву його thinkpad.\necho \u0026#34;thinkpad\u0026#34; \u0026gt; /etc/hostname Також додайте стандартні значення до файлу /etc/hosts:\n1 2 3 4 # Static table lookup for hostnames. # See hosts(5) for details. 127.0.0.1 localhost ::1 localhost Налаштування часового поясу Мій часовий пояс Europe/Kiev, тому в моєму випадку має бути створено це підсумкове посилання:\nln -s /usr/share/zoneinfo/Europe/Kiev /etc/localtime А також рекомендую перевести апаратний годинник BIOS на UTC:\nhwclock --systohc --utc Налаштування initramfs Встановіть пакет lvm2:\npacman -S lvm2 Відредагуйте файл /etc/mkinitcpio.conf і вставте хуки encrypt і lvm2 строго в цьому порядку між хуками block і filesystem, таким чином:\nHOOKS=(base udev ... block encrypt lvm2 filesystems) Потім повторно згенеруйте initramfs:\nmkinitcpio -P Створіть користувача та облікові дані Спочатку рекомендується змінити пароль користувача root:\npasswd root Потім встановіть пакет sudo, щоб дозволити вашому користувачеві надавати привілеї:\npacman -S sudo Потім відредагуйте файл sudoers:\nsudo EDITOR=nano visudo Розкоментуйте рядок %wheel ALL=(ALL:ALL) ALL і збережіть файл.\nСтворіть користувача, змініть пароль і додайте його в потрібні групи:\n1 2 3 useradd -m shifthackz passwd shifthackz usermod -aG wheel,audio,video,storage shifthackz Встановіть необхідні пакети та робоче середовище Це необов’язковий крок, і ви можете зробити те саме після встановлення, але я хотів би мати можливість використовувати DE після встановлення.\nУ цьому прикладі я встановлю Gnome DE (на Wayland і PipeWire) з NetworkManager.\npacman -S gnome networkmanager gnome pipewire \\ pipewire-alsa pipewire-pulse pipewire-jack \\ wireplumber bluez bluez-utils Потім запустіть необхідні служби за замовчуванням\n1 2 3 systemctl enable NetworkManager systemctl enable gdm systemctl enable bluetooth Встановіть завантажувач Я буду використовувати systemd-boot, щоб встановити його, запустіть:\nbootctl install Потім створіть конфігурацію завантажувача в /boot/loader/loader.conf, яка містить таке:\n1 2 3 4 default @saved timeout 3 console-mode max editor no Щоб завантажити мікрокод свого ЦП на початку завантажувача, встановіть пакет amd-ucode або intel-ucode, у моєму випадку у мене процесор Intel, тому команда така:\npacman -S intel-ucode Потім визначте UUID вашого зашифрованого розділу LVM (у моєму випадку /dev/nvme0n1p2):\nblkid /dev/nvme0n1p2 Потім створіть завантажувальний запис для вашої системи Arch Linux у /boot/loader/entries/arch.conf, обов’язково замініть UUID і виправте кореневий розділ у параметрі options:\n1 2 3 4 5 title Arch Linux linux /vmlinuz-linux initrd /intel-ucode.img initrd /initramfs-linux.img options cryptdevice=UUID=b574960c-1d6a-4363-bd8a-0e7345f23e06:luks root=/dev/vg0/lv_root rw Нарешті перевірте bootctl і переконайтеся, що конфігурація правильна в bootctl list.\nПерезавантажтесь у нову систему Для перезавантаження потрібно:\nвведіть exit, щоб вийти з оболонки chroot. потім виконайте umount -R /mnt, щоб відмонтувати ваші розділи. нарешті введіть reboot ","date":"2024-02-24T00:00:00Z","image":"http://localhost:1313/post/arch-linux-install-guide-uefi--encrypted-lvm/header_hue96a0cab901c05107ef04317fe9cfdbe_381439_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D0%B2%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F-arch-linux-uefi--%D0%B7%D0%B0%D1%88%D0%B8%D1%84%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B9-lvm/","title":"Встановлення Arch Linux (UEFI + зашифрований LVM)"},{"content":"Вступ Зазвичай WPS Office пропонує одну з найкращих сумісностей для систем на базі Linux, в особливості що стосується документів пропрієтарних форматів ms office, включаючи документи з складним форматуванням і формулами. Проте, для коректного відображення формул необхідні деякі шрифти, які за замовчуванням відсутні на більшості систем Linux. У такому випадку, після запуску WPS Office ви побачите повідомлення про помилку, яке говорить:\nSome formula symbols might not be displayed correctly due to missing fonts Symbol, Wingdings, Wingdings 2, Wingdings 3, Webdings, MT Extra.\nВиправлення проблеми з шрифтами Для вирішення цієї проблеми достатньо завантажити відсутні шрифти та встановити їх у вашій системі Linux.\nЗавантаження файлів шрифтів Завантажте необхідні шрифти та збережіть їх у яку-небудь папку. Ви можете просто клацнути на кожен файл нижче для його завантаження:\nWEBDINGS.TTF WINGDNG2.ttf WINGDNG3.ttf mtextra.ttf symbol.ttf wingding.ttf Встановлення завантажених шрифтів Створіть папку, яка необхідна для шрифтів формул, найзручніше це зробити увівши команду в термінал:\nsudo mkdir -p /usr/share/fonts/kingsoft Потім скопіюйте завантажені файли до призначеної папки:\n1 2 3 4 5 6 sudo cp WEBDINGS.TTF /usr/share/fonts/kingsoft sudo cp WINGDNG2.ttf /usr/share/fonts/kingsoft sudo cp WINGDNG3.ttf /usr/share/fonts/kingsoft sudo cp mtextra.ttf /usr/share/fonts/kingsoft sudo cp symbol.ttf /usr/share/fonts/kingsoft sudo cp wingding.ttf /usr/share/fonts/kingsoft І зробіть вашого користувача власником цієї папки:\nsudo chown -R $USER:$USER /usr/share/fonts/kingsoft Скасування кешу шрифтів Для скасування кешу шрифтів вашої системи виконайте цю команду:\nsudo fc-cache -vfs Висновок Після встановлення необхідних шрифтів закрийте всі процеси WPS Office та спробуйте запустити його знову. Після запуску помилка не повинна відображатися, і ви зможете використовувати форматування формул.\n","date":"2023-12-15T00:00:00Z","image":"http://localhost:1313/post/fix-missing-formula-fonts-for-wps-office-on-linux/header_huca727e626e0e83a19f41e4803138b60e_99475_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D1%8F%D0%BA-%D0%B2%D0%B8%D0%BF%D1%80%D0%B0%D0%B2%D0%B8%D1%82%D0%B8-%D0%BF%D0%BE%D0%BC%D0%B8%D0%BB%D0%BA%D1%83-%D0%B2%D1%96%D0%B4%D1%81%D1%83%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%96-%D1%88%D1%80%D0%B8%D1%84%D1%82%D1%96%D0%B2-%D1%84%D0%BE%D1%80%D0%BC%D1%83%D0%BB-%D0%B4%D0%BB%D1%8F-wps-office-%D0%BD%D0%B0-linux/","title":"Як виправити помилку відсутності шрифтів формул для WPS Office на Linux"},{"content":"Введення Добре мати ноутбук з Wi-Fi та LTE одночасно, оскільки це фактично забезпечує зарезервований канал підключення до інтернету, що особливо актуально зараз в реаліях 2023 року під час масових перебоїв із зв\u0026rsquo;язком. Ноутбуки серії ThinkPad, як правило, мають підтримку Linux, і багато користувачів успішно використовують модем LTE на цих ноутбуках без додаткової конфігурації. Однак деякі нові моделі поєднуються з модемами Quectel LTE, які мають блокування FCC (FCC lock).\nБлокування FCC Що таке блокування FCC? Блокування FCC - це блокування на рівні програмного забезпечення, інтегроване в модулі WWAN, що постачаються декількома різними виробниками ноутбуків, такими як Lenovo, Dell або HP. Це блокування не дозволяє підключення модулю WWAN до мереді інтернет, поки не буде зроблена певна процедура розблокування (як правило, послідовність команд, що надсилається на модуль драйвером). Детальніше про процедуру блокування/розблокування FCC ви можете прочитати тут.\nЯк ОС обробляє розблокування FCC У системах Windows розблокування FCC зазвичай виконується драйвером, що постачається виробником модему або ноутбука. У Linux системах Modem Manager використовується для забезпечення роботи модему WWAN і насправді має кілька заздалегідь визначених скриптів FCC розблокування для певних відомих модемів WWAN. У деяких випадках виробник постачає скрипти розблокування FCC, особливо це стосується ноутбуків серії ThinkPad, які розроблені в першу чергу бути повністю сумісними з Linux. Але оскільки кожен модем має різний спосіб процедури розблокування FCC, то вона не ввімкнена за замовчуванням, і користувач має вручну включити сценарій розблокування FCC для точної моделі модему. Саме з цієї причини LTE не працює за змовчуванням в системі Linux, що може заплутати деяких користувачів.\nПриклад розблокування FCC Я маю Lenovo ThinkPad X13 Gen2 з процесором Intel з операційною системою Arch Linux, тож даний приклад підходить саме для цього обладнання. Ця процедура досить схожа на інші ноутбуки серії Lenovo ThinkPad, але для вашого обладнання може дещо відрізнятися. Краще за все звернутися на веб-ресурси виробника або на профільні форуми для пошуку точної інформації.\nВизначення моделі модему Перш за все, слід дізнатися точну модель модему LTE ноутбука. Це можна зробити за допомогою команди:\nlspci Команда виведе всі PCI пристрої у системі, тож можна відшукати там модем. У моєму випадку модем LTE був останнім у списку.\n1 2 3 ... 08:00.0 Unassigned class [ff00]: Quectel Wireless Solutions Co., Ltd. EM120R-GL LTE Modem ... Встановлення Modem Manager Переконайтеся, що ви встановили пакет modemmanager.\nВ залежності від вашого Linux дістрибутива, команда може відрізнятися.\nДля ситем на базі Arch: sudo pacman -S modemmanager Для ситем на базі Debian: sudo apt install modemmanager Для ситем на базі Fedora: sudo dnf install modemmanager Після цього треба увімкнути ModemManager.Service в SystemD, це можна зробити за допомогою команди:\nsudo systemctl enable --now ModemManager.service Пошук скрипта для розблокування FCC Цей крок вимагає передбачає пошук скрипта розблокування FCC від виробника або на деяких профільних форумах що стосується вашого конкретного обладнання (ноутбука/модема).\nУ моєму випадку модель модему Quectel EM120R-GL, на щастя, скрипт розблокування FCC постачається з ModemManager. Точний скрипт вдалося знайти на цій сторінці.\nСкрипт в моєму випадку розташовано в /usr/share/ModemManager/fcc-unlock.available.d/1eac:1001, тож щоб застосовувати FCC розблокування автоматично із запуском сервіса ModemManager.service достатньо зробити його лінк до /etc/ModemManager/fcc-unlock.d, наприклад:\nsudo ln -snf /usr/share/ModemManager/fcc-unlock.available.d/1eac:1001 /etc/ModemManager/fcc-unlock.d Далі треба перезапустити ModemManager.service:\nsudo systemctl restart ModemManager.service та спробувати підключитися до LTE, якщо не спрацює то спробувати перезавантажити комп\u0026rsquo;ютер.\nПідключення до LTE мережі Для здійснення підключення до мереж LTE ви можете використовувати або modemmanager у вашому терміналі, або скористатися графічними інструментами налаштувань, наданими NetworkManager у KDE/Gnome. Детальну інформацію щодо виконання мобільних бездротових підключень ви можете знайти на цій сторінці вікі Arch Linux.\nЯ продемонструю обидва методи (через термінал та графічний інтерфейс) на своїй системі.\nПідключення LTE через термінал Спочатку вам потрібно знати індекс WWAN-модема. Для цього виведіть список всіх доступних WWAN-модемів за допомогою mmcli так:\nmmcli -L У виводі знайдіть рядок /org/freedesktop/ModemManager1/Modem/1, індекс модема знаходиться в кінці, у моєму випадку це 1. Цей індекс слід використовувати в усіх командах нижче.\nДалі ви можете спробувати підключитися до мережі LTE, але вам потрібно знати налаштування, які необхідні для вашого постачальника Інтернет-послуг для здійснення підключення. У моєму випадку достатньо лише apn=internet, отже, команда для підключення така:\nmmcli -m 1 --simple-connect=\u0026#34;apn=internet\u0026#34; Якщо підключення вдале, спробуйте переглянути Інтернет або просто виконайте ping 8.8.8.8 в терміналі, щоб переконатися, що ви онлайн.\nПісля завершення перегляду ви можете відключитися від мережі LTE за допомогою команди:\nmmcli -m 1 --simple-connect=\u0026#34;apn=internet\u0026#34; Підключення через графічні налаштування Цей метод передбачає використання робочого середовища, такого як KDE або Gnome, і наявність NetworkManager як основного засобу налаштування мережі у вашій системі Linux. У цьому прикладі я покажу, як це налаштувати в KDE Plasma 5.27.10.\nПо-перше, перейдіть до програми Налаштування системи та відкрийте розділ Підключення.\nНатисніть кнопку + для додавання та оберіть тип підключення Mobile Broadband у відкритому діалозі.\nУ наступному діалозі ви можете обрати конкретний модем для цього підключення, але оскільки у моєї системі є лише один WWAN-модем, я залишу вибір Any GSM device без змін.\nДалі оберіть країну свого постачальника Інтернет-послуг.\nОберіть свого постачальника Інтернет-послуг, або введіть назву вручну, якщо він не вказаний у списку.\nНа цьому етапі оберіть свій тарифний план та переконайтеся, що ви правильно ввели APN, у моєму випадку це \u0026ldquo;internet\u0026rdquo;.\nПісля введення всієї інформації ви повинні побачити вікно успішного завершення.\nKDE спрощує підключення до мережі LTE та моніторинг її стану з іконки лотка. Знайдіть профіль, щойно створений, і натисніть \u0026ldquo;Підключити\u0026rdquo;. Коли ви будете онлайн, статус підключення повинен відображати \u0026ldquo;Підключено\u0026rdquo;, як на знімку екрану.\nВисновок Отже, якщо ваш модем LTE не працює одразу після встановлення Linux, перевірте чи наявне у нього блокування FCC, і шукайте в Інтернеті скрипт для розблокування. У разі, якщо у вас саме такий модем як у мене, Quectel EM120R, ви можете використовувати той же скрипт розблокування FCC що показано у прикладі.\n","date":"2023-12-13T00:00:00Z","image":"http://localhost:1313/post/how-to-make-thinkpad-lte-modem-work-on-arch-linux-using-fcc-unlock/header_hu2d109c230a8b683de6314808740ea101_247945_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D0%BD%D0%B0%D0%BB%D0%B0%D1%88%D1%82%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-lte-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BC%D1%83-%D0%B2%D0%B1%D1%83%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE-%D0%B2-%D0%BD%D0%BE%D1%83%D1%82%D0%B1%D1%83%D0%BA-thinkpad-%D0%BD%D0%B0-arch-linux-%D0%B7%D0%B0-%D0%B4%D0%BE%D0%BF%D0%BE%D0%BC%D0%BE%D0%B3%D0%BE%D1%8E-fcc-unlock/","title":"Налаштування LTE модему вбудованного в ноутбук ThinkPad на Arch Linux за допомогою FCC unlock"},{"content":"Введення Zsh, або Z Shell, — це потужна та багатофункціональна оболонка командного рядка для Unix-подібних операційних систем, включаючи Linux і BSD (Berkeley Software Distribution). Це розширена версія Bourne Shell (sh) з численними вдосконаленнями та додатковими функціями. Zsh має на меті забезпечити більш інтерактивний і зручний досвід для користувачів оболонки.\nОсь кілька причин, чому Zsh часто вважають однією з найкращих оболонок для систем Unix/Linux/BSD:\nРедагування командного рядка: Zsh пропонує розширені можливості редагування командного рядка, що дозволяє користувачам легко переходити та редагувати команди. Він підтримує такі функції, як розширення історії, виправлення орфографії та вдосконалене зіставлення шаблонів.\nНалаштування: Zsh можна налаштувати. Користувачі можуть налаштовувати різні аспекти поведінки оболонки, такі як швидкий вигляд, прив’язки клавіш і параметри завершення. Великі параметри конфігурації дозволяють адаптувати його до індивідуальних уподобань і робочих процесів.\nАвтодоповлення команд: Zsh забезпечує Автодоповлення команд з урахуванням контексту, полегшуючи навігацію файловою системою та завершуючи імена та аргументи команд. Він може завершувати не лише команди, але й шляхи до файлів, змінні тощо.\nПлагіни та розширення: Zsh підтримує плагіни та розширення, які покращують його функціональність. Такі інструменти, як Oh-My-Zsh і Prezto, є популярними фреймворками, які спрощують керування конфігураціями Zsh і додають додаткові функції за допомогою плагінів.\nВиправлення орфографії: Zsh має вбудовану функцію виправлення орфографії, яка допомагає користувачам уникати помилок. Якщо ви неправильно введете команду або шлях до файлу, Zsh може запропонувати виправлення.\nІнтерактивні функції: Zsh містить інтерактивні функції, які покращують загальну взаємодію з користувачем, наприклад можливість легко переглядати історію команд, здійснювати пошук серед попередніх команд і повторно використовувати або ефективно змінювати команди.\nСумісність із оболонкою Bourne: Zsh сумісний із синтаксисом оболонки Bourne (sh), що робить його відповідною заміною для sh або Bash. Існуючі сценарії оболонки, швидше за все, працюватимуть у Zsh без змін.\nХоча Zsh пропонує багатий набір функцій, вибір «найкращої» оболонки часто залежить від індивідуальних уподобань і конкретних випадків використання. Інші популярні оболонки включають Bash (Bourne Again SHell) і Fish (Friendly Interactive SHell), кожна з яких має свої сильні сторони та характеристики. Зрештою, найкраща оболонка — це та, яка узгоджується з вашим робочим процесом і відповідає вашим конкретним вимогам.\nВстановлення Встановіть пакет ZSH Щоб установити пакет ZSH у вашій системі Linux, розгляньте можливість використання менеджера пакунків, який постачається з вашим дистрибутивом. Це робиться по-різному залежно від вашого дистрибутива, наприклад:\nДля Arch Linux:\nsudo pacman -S zsh Для Fedora, Red Hat:\nsudo dnf install zsh Для Debian, Ubuntu, Linux Mint, ElementaryOS:\nsudo apt install zsh У моєму випадку я встановлюю його для Arch Linux:\nВстановлення ZSH оболонкою за замовчуванням Щоб зробити новий встановлений ZSH стандартним для вашого користувача, введіть команду нижче та введіть свій пароль користувача для підтвердження:\nchsh -s $(which zsh) Після цього рекомендується перезавантажити систему, при наступному перезавантаженні оболонка ZSH буде використана для вашого користувача. Щоб перезавантажити комп’ютер, ви можете скористатися командою sudo reboot або просто скористатися графічним інтерфейсом робочого середовища для виконання перезавантаження.\nПерше налаштування Щойно ви відкриєте програму терміналу після перезавантаження, zsh запропонує вам створити файли конфігурації за замовчуванням. Для застосування конфігурації натисніть на клавіатурі «0».\nВстановлення Oh My ZSH Oh My Zsh — це платформа з відкритим вихідним кодом і менеджер конфігурації для Zsh, Z Shell. Він був створений, щоб полегшити користувачам керування конфігураціями Zsh і покращити роботу командного рядка. Oh-My-Zsh надає колекцію плагінів, тем і допоміжних функцій, які можна легко інтегрувати в Zsh, дозволяючи користувачам налаштовувати та розширювати функціональність свого середовища оболонки.\nНайпростіший спосіб щоб інсталювати ZSH — скористатися сценарієм інсталяції зі Oh My Zsh GitHub Repository. Можна виконати інсталяційний сценарій, завантаживши його, ось так:\nsh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; Після завершення скрипта ви побачите встановлену оболонку Oh My Zsh, як на знімку екрана нижче.\nНалаштування теми Oh My ZSH Oh My Zsh має багато попередньо встановлених тем, які знаходяться в папці ~/.oh-my-zsh/themes/.\nВи можете змінити свій файл .zshrc і використовувати попередньо встановлену тему.\nnano .zshrc А щоб змінити тему на agnoster, наприклад, знайдіть параметр ZSH_THEME і змініть його так:\nZSH_THEME=\u0026#34;agnoster\u0026#34; Встановлення сторонної теми Oh My ZSH Особисто мені тема Powerlevel10k найбільше подобається серед інших, тому в цьому прикладі я покажу, як її встановити.\nВстановлення сумісного шрифта терміналу Щоб тема могла правильно відображати деякі символи, ваш термінал має використовувати спеціальний сумісний фон Meslo LGS NF. Для цього ви можете виконати інструкції зі сховища GitHub.\nНайпростіший спосіб - завантажити 4 файли шрифтів:\nMesloLGS NF Regular.ttf MesloLGS NF Bold.ttf MesloLGS NF Italic.ttf MesloLGS NF Bold Italic.ttf Щоб зробити їх доступними для всієї системи, перемістіть ці 4 файли до папки /usr/share/fonts:\n1 2 3 4 sudo mv \u0026#34;MesloLGS NF Regular.ttf\u0026#34; /usr/share/fonts sudo mv \u0026#34;MesloLGS NF Bold.ttf\u0026#34; /usr/share/fonts sudo mv \u0026#34;MesloLGS NF Italic.ttf\u0026#34; /usr/share/fonts sudo mv \u0026#34;MesloLGS NF Bold Italic.ttf\u0026#34; /usr/share/fonts Щоб очистити кеш шрифтів, виконайте команду:\nsudo fc-cache Останнім кроком є зміна шрифту вашого терміналу. Це може залежати від терміналу, який ви використовуєте, але зазвичай ви можете просто змінити його в графічних налаштуваннях терміналу. У моєму випадку я налаштував його на використання Meslo LGS NF Regular 12.\nВстановлення теми Powerlevel10k Спочатку завантажте тему Powerlevel10k у свій каталог користувальницьких тем, це можна легко зробити за допомогою однієї команди:\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k Потім змініть файл .zshrc:\nnano .zshrc і встановіть параметр ZSH_THEME рівним powerlevel10k/powerlevel10k:\nZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; Після збереження файлу скористайтеся наведеною нижче командою, щоб застосувати зміни:\nsource ~/.zshrc Перше налаштування Powerlevel10k Під час першого запуску нового спеціального рівня Powerlevel10k запуститься майстер налаштування теми Powerlevel10k. Ви завжди можете знову запустити цей майстер, використовуючи команду терміналу p10k configure. Майстер має кілька кроків, просто натисніть відповідні клавіші на клавіатурі, щоб відповісти. Нижче я покажу, як конфігурація виглядає в моєму випадку.\n1. Переконайтеся, що кілька символів шрифту відображаються правильно. Я просто відповів «так» на ці запитання (натиснувши «y» на клавіатурі), тому що все, що стосується відтворення символів, відображалося правильно.\n2. Налаштуйте стиль теми Усі параметри в цьому розділі дозволяють змінити дизайн теми відповідно до ваших особистих уподобань. Я покажу, які відповіді я ввів у майстер, якщо ви захочете відтворити точну поведінку теми з цього посібника.\nШвидке налаштування стилю дозволить налаштувати основний вигляд і відчуття, тут я відповів «3». Набір символів є важливим параметром, і насправді Юнікод дозволяє відображати більше символів, тому я настійно рекомендую відповісти тут «1». Цей параметр дозволяє показувати або приховувати поточний час у терміналі. Я не бачу в цьому жодної практичної користі, тому відповів n тут. Наступні налаштування стосуються зовнішнього вигляду теми, ви можете вибрати те, що вам подобається особисто.\nФункція instant prompt дозволяє скоротити час завантаження оболонки ZSH, тому я настійно рекомендую ввімкнути її, відповівши тут «1». Останнім кроком є застосування змін до .zshrc, просто дайте тут відповідь y. Якщо все налаштовано правильно, ви побачите нову тему оболонки.\nУвімкніть вбудовані плагіни Oh My ZSH Zsh підтримує плагіни та розширення, які покращують його функціональність. Oh-My-Zsh дозволяє легко керувати конфігураціями Zsh і додавати додаткові функції за допомогою плагінів.\nЩоб переглянути список плагінів, які входять до складу Oh My ZSH, ви можете ввести команду:\nls -a ~/.oh-my-zsh/plugins/ У моєму випадку у мене є такі плагіни:\nПотім ви можете змінити свій файл .zshrc:\nnano .zshrc і встановити параметр plugins для завантаження потрібних вам плагінів, у моєму випадку (як розробника Android) мені потрібні плагіни git і adb:\nplugins=(git adb) Потім застосуйте зміни до оболонки:\nsource ~/.zshrc Встановлення сторонніх плагінів Також Oh My ZSH дозволяє встановлювати та використовувати сторонні плагіни. Наприклад, давайте встановимо плагіни zsh-autosuggestions, щоб мати хороші рекомендації щодо команд введення на основі історії.\nВстановлення дуже схоже на встановлення спеціальної теми. Спочатку клонуйте плагін у каталог настроюваних плагінів.\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions Тоді ви можете змінити свій файл .zshrc так само, як я показав у розділі статті вище, тому в результаті ви матимете:\nplugins=(git adb zsh-autosuggestions) Потім застосуйте зміни до оболонки:\nsource ~/.zshrc Після цього спробуйте щось набрати, і ви побачите пропозицію. Наприклад, я ввів \u0026ldquo;neo\u0026rdquo;, а плагін пропонує використовувати \u0026ldquo;neofetch\u0026rdquo;:\nУвімкнення автоматичних оновлень Oh-My-Zsh має вбудований механізм оновлення, який допомагає користувачам підтримувати інсталяцію в актуальному стані за допомогою останніх змін, удосконалень і виправлень помилок, внесених спільнотою. Він також надає можливість автоматичного оновлення, але за умовчанням його вимкнено.\nЩоб налаштувати автоматичне оновлення, вам слід встановити цю директиву у файлі .zshrc:\nzstyle \u0026#39;:omz:update\u0026#39; mode auto Висновки Таким чином, ZSH є більш багатофункціональною оболонкою, яка може зробити вашу роботу ефективнішою, розширюючи функціональність оболонки за допомогою спеціальних плагінів, тому її можна вважати кращою альтернативою bash, яка є оболонкою за замовчуванням у будь-якому сучасному дистрибутиві Linux.\n","date":"2023-11-26T00:00:00Z","image":"http://localhost:1313/post/how-to-install-and-configure-zsh-shell-in-linux/header_hu6914af8cdb8921216861b6ef227624ec_122422_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D1%8F%D0%BA-%D0%B2%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%B8%D1%82%D0%B8-%D1%82%D0%B0-%D0%BD%D0%B0%D0%BB%D0%B0%D1%88%D1%82%D1%83%D0%B2%D0%B0%D1%82%D0%B8-zsh-%D1%83-linux/","title":"Як встановити та налаштувати ZSH у Linux"},{"content":"Введення Використовуючи systemd-boot як завантажувач, більш зручно, щоб система запам’ятовувала останню вибрану опцію під час кожного наступного завантаження. Це особливо корисно для користувачів, які використовують різниі операційні системи або ядра Linux. Налаштувавши systemd-boot на запам\u0026rsquo;ятовування останньої вибраної опції завантаження, ви можете спростити процес завантаження та уникнути необхідності вручну вибирати потрібний параметр кожного разу, коли система перезавантажується.\nЗміна конфігураційного файлу Щоб налаштувати запам\u0026rsquo;ятовування systemd-boot, потрібно змінити файл конфігурації `loader.conf``. Точне розташування цього файлу може відрізнятися залежно від дистрибутива Linux, який ви використовуєте.\nОсобисто я використовував кілька дистрибутивів Linux, і шлях до loader.conf був різним у кожному з них, наприклад:\nДля Ubuntu це було /boot/efi/loader/loader.conf Для Arch Linux це було /boot/loader/loader.conf Для EndeavourOS це був /efi/loader/loader.conf Щоб змінити файл, відкрийте термінал і виконайте такі дії:\nВідкрийте файл loader.conf для редагування, наприклад: sudo nano /boot/loader/loader.conf Змініть параметр default, як показано нижче: default @saved Збережіть файл (В nano це робиться клавіатурним скороченням Crtl + O). Після того як ви виберете деяку опцію (ОС чи ядро) при завантаженні комп\u0026rsquo;ютера в systemd-boot, то її буде збережено та запропоновано автоматично як стандартниу під час наступного завантаження.\nВисновки Налаштувавши systemd-boot на запам\u0026rsquo;ятовування останньої вибраної опції, ви можете оптимізувати процес завантаження та покращити загальну взаємодію з користувачем. Незалежно від того, чи використовуєте ви Arch Linux, Ubuntu або інший дистрибутив, який використовує systemd-boot, ця проста модифікація може заощадити ваш час і зробити запуск вашої системи ефективнішим.\nНе забудьте адаптувати шляхи до файлів і команди відповідно до специфіки вашого дистрибутива. З цією конфігурацією ваша система автоматично завантажуватиметься з останнього вибраного запису, зменшуючи потребу в ручному втручанні під час процесу завантаження.\n","date":"2023-11-22T00:00:00Z","image":"http://localhost:1313/post/how-to-make-systemd-boot-remember-the-last-selected-entry/header_hu0e765b8aca8d9ba54a80770b06516939_1619_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/uk/post/%D0%BD%D0%B0%D0%BB%D0%B0%D1%88%D1%82%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-systemd-boot-%D0%B4%D0%BB%D1%8F-%D0%B7%D0%B0%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D0%BE%D0%B2%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-%D0%BE%D1%81%D1%82%D0%B0%D0%BD%D0%BD%D1%8C%D0%BE%D1%97-%D0%B2%D0%B8%D0%B1%D1%80%D0%B0%D0%BD%D0%BE%D1%97-%D0%BE%D0%BF%D1%86%D1%96%D1%97/","title":"Налаштування systemd-boot для запам'ятовування останньої вибраної опції"},{"content":"Введення Наразі існує дуже багато платформ для онлайн-стримінгу відеоконтенту, такі як YouTube, Twitch, та інші. Для трансляції потокового відео через мережу інтернет вони використовують прокотол RTMP (Real-Time Messaging Protocol). Хоча ці платформи мають потужні можливості для проведення відеотрансляцій, в деяких випадках незалежність від стримінгової платформи та її правил є цілком доцільною.\nУ цій статті наведемо інструкцію з деплойменту RTMP сервіса на базі Nginx-RTMP, що дозволить приймати RTMP потік від комп\u0026rsquo;ютера стримера, та конвертувати його в сучасні формати HLS та DASH для перегляду у програмі-приймачі.\nПередумови Для реалізації RTMP сервісу, вам потрібно мати:\nНову віртуальну машину або фізичний сервер на базі ОС Linux. Комп\u0026rsquo;ютер для ведення трансляції. Для роботи поза локальною мережею, в глобальній мережі інтернет:\nВиділену IP адресу. Домен. В інструкції буде використано VPS на базі Debian 11.\nРобота з Nginx-RTMP Встановлення Перш за все, необхідно встановити пакети nginx та libnginx-mod-rtmp. Для цього потрібно виконати команди:\n1 2 sudo apt update sudo apt install nginx libnginx-mod-rtmp Налаштування RTMP Після встановлення, потрібно сконфігурувати веб-сервер Nginx таким чином, щоб він прослуховував порт 1935 для отримання RTMP-потоку. Для цього потрібно відредагувати файл /etc/nginx/nginx.conf:\nsudo nano /etc/nginx/nginx.conf В кінці файла, потрібно дописати конфігурацію RTMP сервера:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ... rtmp { server { listen 1935; chunk_size 4096; allow publish 127.0.0.1; allow publish 192.168.0.0/24; deny publish all; application live { live on; record off; hls on; hls_path /var/www/html/stream/hls; hls_fragment 3; hls_playlist_length 60; dash on; dash_path /var/www/html/stream/dash; } } } ... Тлумачення важливих аспектів цієї конфігурації:\nlisten 1935 - задає порт, на якому працює RTMP сервер. chunk_size 4096 - задає розмір блоку, по 4 Кб. allow publish [IP / Subnet] - кожна строка вказує IP або підмережу, яким дозволено відсилати RTMP потік на сервер. deny publish all - забороняє приймати RTMP потік від всіх інших адрес/мереж. application live - конфігурація для перетворення RTMP в формати HLS та DASH, де hls_path та dash_path вказують шляхи до каталогів для розміщення плейлистів. live on - дозволяє приймати дані відеопотоком. record off - вимикає запис відеопотоку у файл на диску. Налаштвання HLS, DASH Далі, необхідно розгорнути віртуальний хост, що дозволить отримувати доступ до HLS або DASH потоків через HTTP/HTTPS протокол.\nСпочатку треба створити дві директорії для зберігання фрагментів відеопотоку для HLS та DASH:\n1 2 sudo mkdir -p /var/www/html/stream/hls sudo mkdir -p /var/www/html/stream/dash Та також встановити власника та права:\n1 2 sudo chown -R www-data:www-data /var/www/html/stream sudo chmod -R 755 /var/www/html/stream Для роботи віртуального хоста, потрібно створити новий конфігураційний файл (наприклад rtmp) в каталозі /etc/nginx/sites-available:\nsudo nano /etc/nginx/sites-available/rtmp Хост файл rtmp складається з наступного:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 443 ssl; listen 80; server_name rtmp.yourdomain.com; ssl_certificate /etc/ssl/yourdomain.crt; ssl_certificate_key /etc/ssl/yourdomain.key; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; location / { add_header Access-Control-Allow-Origin *; root /var/www/html/stream; } } types { application/dash+xml mpd; } Пояснення до цієї конфігурації:\nЗамініть rtmp.yourdomain.com на свій домен. Якщо ви хочете використовувати SSL, то також запишіть файли сертифікату та ключа за шляхами /etc/ssl/yourdomain.crt та /etc/ssl/yourdomain.key. Якщо ви не хочете використовувати SSL, то приберіть з файлу рядки що починаються з ssl та listen 443 ssl. Для того щоб всі зроблені конфігурації вступили в дію, треба увімкнути віртуальний хост та перезавантажити Nginx:\n1 2 sudo ln -s /etc/nginx/sites-available/rtmp /etc/nginx/sites-enabled/ sudo service nginx restart Ведення трансляції в OBS Studio Для ведення трансляції найкраще за все підходить програма OBS Studio.\nПершочергово необхідно створити сцену, налаштувати звук, та зовнішній вигляд трансляції.\nДля налаштування параметрів стримінгу, потрібно зайти в Налаштування та вибрати вкладку Stream. Там необхідно задати наступні параметри:\nService: Custom Server: rtmp://rtmp.yourdomain.com/live (замість домену можна вказати IP, наприклад http://11.22.33.44/live) Stream Key: obs_stream Приклад налаштувань:\nДля запуску відеотрансляції, необхідно натиснути Start Streaming в головномі вікні програми:\nПерегляд трансляції Тепер трансляцію можна переглянути за допомогою будь-якої програми, що підтримує протоколи HLS та DASH. Найпростішим шляхом буде перегляд у програмі VLC, відкривши посилання на потік.\nДля початку, розберемося як формується посилання на потоки в сконфігурованому сервісі:\nHLS: {protocol}://{domain}/hls/{stream key}.m3u8 DASH: {protocol}://{domain}/dash/{stream key}.mpd Наприлкад, якщо ви розгорнули сервіс за адресою rtmp.yourdomain.com що використовує SSL, та в налаштуваннях OBS вказали ключ obs_stream, то в такому випадку посилання будуть такими:\n1 2 https://rtmp.yourdomain.com/hls/obs_stream.m3u8 https://rtmp.yourdomain.com/dash/obs_stream.mpd Для перегляду в VLC, потрібно натиснути Ctrl + N, або перейти в меню Media \u0026gt; Open Network Stream, вказати посилання на один із форматів, та натиснути Play.\nВисновки Таким чином можна створити свій сервіс для проведення трансляцій, що буде незалежним від популярних сервісів.\nПереваги такого рішення:\nПриватність та повний контроль над інфраструктурою, гарантія що дані потоку не зберігаються. Не потрібно дотримуватися правил сервісу (наприклад заборону транслювати певний контент). Але є і певні недоліки:\nТаке рішення вимагає певних ресурсів сервера. Власнику потрібно витрачати час та кошти на обслуговування та підтримку безпеки своєї інфраструктури. ","date":"2022-07-20T00:00:00Z","image":"http://localhost:1313/post/deploying-an-rtmp-server-for-streaming-using-nginx-rtmp/header_hu41968337912a42023606e3de60723367_1230034_120x120_fill_q75_box_smart1.jpeg","permalink":"http://localhost:1313/uk/post/%D1%80%D0%BE%D0%B7%D0%B3%D0%BE%D1%80%D1%82%D0%B0%D0%BD%D0%BD%D1%8F-rtmp-%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D0%B0-%D0%B4%D0%BB%D1%8F-%D1%81%D1%82%D1%80%D0%B8%D0%BC%D1%96%D0%BD%D0%B3%D1%83-%D0%B2%D0%B8%D0%BA%D0%BE%D1%80%D0%B8%D1%81%D1%82%D0%BE%D0%B2%D1%83%D1%8E%D1%87%D0%B8-nginx-rtmp/","title":"Розгортання RTMP сервера для стримінгу, використовуючи Nginx RTMP"},{"content":"Введення Tor - програмний комплекс з відкритим вихідним кодом, який об\u0026rsquo;єднує певні комп\u0026rsquo;ютери по всьому світу в систему проксі-серверів, з\u0026rsquo;єднання між якими здійснюються за схемою цибулинної маршрутизації. Це дозволяє користувачам цієї мережі встановлювати анонімне з\u0026rsquo;єднання, захищене від прослуховування.\nОсновне призначення мережі Tor на сьогоднішній день – забезпечення анонімності для користувачів інтернету, дозволяючи приховувати свою особу під час перегляду сайтів від провайдера, власників сайтів, рекламних роботів, автоматизованих систем аналізу трафіку тощо. Це досягається за рахунок великої розподіленої системи серверів – вузлів, трафік між якими маршрутизується на мережному рівні за моделлю OSI.\nРолі суб\u0026rsquo;єктів мережі Tor Знаючи, що мережа складається з серверів-вузлів, з\u0026rsquo;єднаних до цибулинної мережі, розглянемо які вузли є в мережі Tor:\nВхідний вузол (Entry Node) Вхідний вузол є першою ланкою в ланцюжку з\u0026rsquo;єднання. Він ініціює встановлення захищеного з\u0026rsquo;єднання, приймаючи пакети від користувача Tor, шифрує їх та передає наступному вузлу. Зазначимо, що перехоплення даних між користувачем та вхідним вузлом неможливе, оскільки кожен блок зашифрований сеансовим ключем із застосуванням гібридного шифрування.\nВузол-посередник (Middle Node) Завдання цих вузлів зводиться лише для того, щоб прийняти дані від попереднього вузла, зашифрувати їх і передати наступному. З такого сайту неможливий вихід за межі мережі Tor в інтернет. З такого вузла можна хіба що потрапити на сайту внутрішньомережевого домену .onion, не більше. Але ці вузли дуже важливі для підтримки працездатності мережі: що більше посередників у ланцюжку — то вища анонімність, і ймовірність компрометації вашого з\u0026rsquo;єднання зменшується. Крім того, встановити через які саме вузли-посередники проходить ваш ланцюжок не можна, оскільки IP-адреси таких вузлів не записуються в лог-файл.\nВихідний вузол (Exit Node) Це останній вузол у ланцюжку Tor. Він розшифровує пакети, передані користувачем по всьому ланцюжку, і передає дані до віддаленого сервера, що запитується, в мережі інтернет. На сервері, що запитується, буде зафіксовано підключення з IP-адреси вихідного вузла. Дані види вузлів є найслабшим місцем мережі Tor, оскільки існують способи перехоплення даних користувача між вихідним вузлом та віддаленим сервером. Також доброволець, який запустив у себе Exit Node, наражає себе на ризик виникнення проблем, оскільки саме його IP фіксується інтернет ресурсами.\nМостовий вузол (Bridge Relay) Це ретранслятори, адреси яких доступні публічно. Вони служать для ініціювання з\u0026rsquo;єднання в місцях, де адреси кореневих серверів Tor заблоковані. Отримати адресу мостового вузла можна, прийнявши e-mail від TheTorProject за спеціальним запитом. Таким чином, навіть тотальне блокування всіх публічно відомих адрес вузлів мережі Tor не дасть жодного результату, оскільки це не вплине на доступність засекречених ретрансляторів.\nВихідний енклав (Exit Enclave) Ретранслятор, який використовується власниками сайтів для створення дзеркала свого ресурсу в мережі Tor. Це дозволить користувачам деяких країн обійти блокування, а решті зберегти анонімність, захистивши себе вкотре від перехоплення трафіку з вихідного вузла.\nЯк виглядає ланцюжок між користувачем та кінцевим інтернет ресурсом, продемонстровано на схемі нижче:\nОсобливості Tor Також Tor, починаючи з 2004 року, може забезпечити анонімність і для серверів. Кожен користувач мережі може розмістити будь-який сервіс, так званому внутрішньому домені .onion, який складається з випадкового набору символів. Такий сервіс буде доступний тільки з мережі Tor, причому ні користувачі не зможуть дізнатися про публічний IP прихованого сайту, ні адміністратор сайту не зможе знати хто його відвідувачі. У логах сервера буде доступний лише факт відвідування сайту та конкретний відвідуваний користувачем каталог.\nАле потрібно бути обережними при використанні Tor, тому що в ній є наступні особливості що варто мати на увазі при використанні Tor:\nВхідному вузлу відома IP-адреса користувача; На вихідному вузлі повідомлення повністю розшифровується, але відправник невідомий; На віддаленому сервері, що запитується, разом з пакетом передаються деякі технічні дані про відправника, хоча по суті відправник невідомий; Пакети з вашим повідомленням можуть проходити вузлами, які були запущені зловмисниками з метою розкрадання ваших даних; Інтернет ресурс може отримати дані про конфігурацію ПК та версію ОС користувача, а також його IP-адресу шляхом виконання на сторінці JavaScript, Flash, ActiveX скриптів; На шляху від вихідного вузла до кінцевого сервера дані можуть підмінені внаслідок проведення Man-In-The-Middle атаки, тому якщо ви, наприклад, завантажуєте файл через Tor, завжди звіряйте його хеш-суми; Власник вихідного вузла може вкрасти вашу сесію, файли cookie, і навіть логіни та паролі шляхом перехоплення даних за допомогою SSL Strip; Оскільки IP-адреси вихідних вузлів доступні публічно, деякі інтернет-провайдери та сайти їх блокують (наприклад Google, VK); Висновки Можна зробити висновок, що мережа Tor має велику цінність для тих, хто піддається масовому стеженню, для тих, хто цінує свободу в інтернеті, для тих, хто не хоче миритися з масштабними безглуздими блокуваннями, для тих, хто хоче мати хоча б маленький острівець анонімності.\nБудьте обережні в інтернеті, тому що можливо прямо зараз коли ви читаєте це, дехто дивиться на ваш трафік 😱.\n","date":"2016-10-07T00:00:00Z","image":"http://localhost:1313/post/how-the-tor-network-actually-works/header_hu447e204f4d18572619e9ad6f34ad1dde_86330_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D0%BE%D1%81%D0%BE%D0%B1%D0%BB%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D1%96-%D1%80%D0%BE%D0%B1%D0%BE%D1%82%D0%B8-tor/","title":"Особливості роботи Tor"},{"content":"Введення Mega.nz одне з найдоступніших хмарних сховищ за об\u0026rsquo;ємом, адже надає своїм новим користувачам 50Gb хмарного дискового простору абсолютно безкоштовно. Є також платні тарифи, які дозволяють розширити хмару аж до 4 терабайт. Але для резервних копій сайтів та баз даних MySQL цілком вистачає навіть 50Gb. Також, є набір консольних утиліт megatools для скачування та вивантаження файлів на віддалену хмару.\nНалаштування Встановлення megatools Для початку зареєструйте та активуйте собі обліковий запис на сайті mega.nz, якщо у вас його досі немає.\nДалі треба підключитися до сервера по SSH, та встановити необхідні для збирання megatools пакети:\nsudo apt-get -y install build-essential libglib2.0-dev libssl-dev libcurl4-openssl-dev libgirepository1.0-dev Після цього на офіційному сайті варто знайти посилання на завантаження megatools, яке потім використовуємо для завантаження командою wget.\n1 2 3 cd /opt wget https://megatools.megous.com/builds/megatools-1.9.97.tar.gz tar -xvzf megatools-1.9.97.tar.gz Після того як ми завантажили та розархівували вихідний код, треба його скомпілювати. Це можна зробити за допомогою наступної послідовності команд:\n1 2 3 4 cd megatools-1.9.97 ./configure make make install Якщо все скомпілювалося і встановилося без помилок, можна переходити до наступного етапу, а саме написання скрипта для створення і вивантаження бекапів в хмару.\nСтворення скрипта для резервного копіювання Спочатку створюємо файл із даними для входу до облікового запису:\n1 2 cd ~ nano .megarc Файл має бути наповнено таким чином:\n1 2 3 [Login] Username = {Ваш логін} Password = {Ваш пароль} Так як у нас дані для входу зберігаються у відкритому вигляді, зробимо їх доступними лише для root.\nchmod 640 .megarc Тепер перевіримо правильність введення логіну з паролем, для цього вводимо команду:\nmegals Якщо всі налаштування корректні, вона має вивести на екран список файлів. Якщо команда не вивела список файлів, то перевіряємо правильність введення пароля, якщо вивела, то переходимо до наступного кроку створення скрипту для бекапу. В даному випадку скрипти зберігаються в директорії /opt/scripts з модифікованими правами.\nnano /opt/scripts/do_backup.sh Скрипт виглядає так:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/bin/bash SERVER=\u0026#34;server\u0026#34; DAYS_TO_BACKUP=7 WORKING_DIR=\u0026#34;/root/tmp_dir\u0026#34; BACKUP_MYSQL=\u0026#34;true\u0026#34; MYSQL_USER=\u0026#34;{Ваш користувач MySQL}\u0026#34; MYSQL_PASSWORD=\u0026#34;{Ваш пароль користувача MySQL}\u0026#34; DOMAINS_FOLDER=\u0026#34;/var/www\u0026#34; ################################## # Створюємо тимчасову папку для створення архівів rm -rf ${WORKING_DIR} mkdir ${WORKING_DIR} cd ${WORKING_DIR} # Архівуємо папку /etc cd / tar cJf ${WORKING_DIR}/etc.tar.gx etc cd - \u0026gt; /dev/null # Бекап бази даних MySQL if [ \u0026#34;${BACKUP_MYSQL}\u0026#34; = \u0026#34;true\u0026#34; ] then mkdir ${WORKING_DIR}/mysql for db in $(mysql -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e \u0026#39;show databases;\u0026#39; | grep -Ev \u0026#34;^(Database|mysql|information_schema|performance_schema|phpmyadmin)$\u0026#34;) do #echo \u0026#34;processing ${db}\u0026#34; mysqldump --opt -u${MYSQL_USER} -p${MYSQL_PASSWORD} \u0026#34;${db}\u0026#34; | gzip \u0026gt; ${WORKING_DIR}/mysql/${db}_$(date +%F_%T).sql.gz done #echo \u0026#34;all db now\u0026#34; mysqldump --opt -u${MYSQL_USER} -p${MYSQL_PASSWORD} --events --ignore-table=mysql.event --all-databases | gzip \u0026gt; ${WORKING_DIR}/mysql/ALL_DATABASES_$(date +%F_%T).sql.gz fi # Бекап сайтів mkdir ${WORKING_DIR}/domains for folder in $(find ${DOMAINS_FOLDER} -mindepth 1 -maxdepth 1 -type d) do cd $(dirname ${folder}) tar cJf ${WORKING_DIR}/domains/$(basename ${folder}).tar.xz $(basename ${folder}) cd - \u0026gt; /dev/null done ################################## # Захищаємось від помилок dbus-error export $(dbus-launch) # Створюємо на хмарі папку з ім\u0026#39;ям сервера, а в ній ще одну з сьогоднішньою датою [ -z \u0026#34;$(megals --reload /Root/backup_${SERVER})\u0026#34; ] \u0026amp;\u0026amp; megamkdir /Root/backup_${SERVER} # Очистка старих непотрібних логів while [ $(megals --reload /Root/backup_${SERVER} | grep -E \u0026#34;/Root/backup_${SERVER}/[0-9]{4}-[0-9]{2}-[0-9]{2}$\u0026#34; | wc -l) -gt ${DAYS_TO_BACKUP} ] do TO_REMOVE=$(megals --reload /Root/backup_${SERVER} | grep -E \u0026#34;/Root/backup_${SERVER}/[0-9]{4}-[0-9]{2}-[0-9]{2}$\u0026#34; | sort | head -n 1) megarm ${TO_REMOVE} done # Створюємо папку curday=$(date +%F) megamkdir /Root/backup_${SERVER}/${curday} 2\u0026gt; /dev/null # Завантажуємо файли на віддалену хмару megacopy --reload --no-progress --local ${WORKING_DIR} --remote /Root/backup_${SERVER}/${curday} \u0026gt; /dev/null # Вбиваємо DBUS-daemon kill ${DBUS_SESSION_BUS_PID} rm -f ${DBUS_SESSION_BUS_ADDRESS} # Видаляємо тимчасові файли rm -rf ${WORKING_DIR} exit 0 Тепер потрібно дозволити виконання скрипта:\nchmod a+x /opt/scripts/do_backup.sh Далі необхідно протестувати скрипт, безпосередньо виконавши його:\n/opt/scripts/do_backup.sh Після цього можна зайти на аккаунт mega через веб-інтерфейс, та перевірити що там з\u0026rsquo;явилися потрібні файли.\nСтворення правила автозапуску скрипта в crontab Тепер щоб скрипт запускався за певним тимчасовим розкладом, додамо його до crontab.\n04 04 * * * root /opt/scripts/do_backup.sh Оптимальність використання В моєму випадку папка з бекапом має розмір 538,8 Mb.\nВсього на хмарі 50000 Mb вільного місця. Нехай у нас кожен бекап приблизно важить 550 Mb. Ділимо 50000 на 550, маємо:\n50000 / 550 ≈ 90.9 Це означає, що хмари вистачить на 90 бекапів, що досить велика цифра, особливо якщо врахувати безкоштовність сервісу Mega.\nАле оптимальність вцілому залежить від чинників:\nРозмір бекапу Частота резервного копіювання Тривалість зберігання кожного бекапу Тому для кожного окремого випадку доцільно оцінювати оптимальність окремо.\n","date":"2016-10-02T00:00:00Z","image":"http://localhost:1313/post/automatic-server-backup-to-the-mega.nz-cloud/header_hu07d9fa8bf00f81164ad47a9c5dedba00_591360_120x120_fill_q75_box_smart1.jpg","permalink":"http://localhost:1313/uk/post/%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%BD%D0%B8%D0%B5-%D1%80%D0%B5%D0%B7%D0%B5%D1%80%D0%B2%D0%BD%D0%B5-%D0%BA%D0%BE%D0%BF%D1%96%D1%8E%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F-%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D0%B0-%D0%B2-%D1%85%D0%BC%D0%B0%D1%80%D0%BD%D0%B5-%D1%81%D0%B5%D1%80%D0%B5%D0%B4%D0%BE%D0%B2%D0%B8%D1%89%D0%B5-mega.nz/","title":"Автоматичние резервне копіювання сервера в хмарне середовище Mega.nz"},{"content":"Введення SSH Тунелі дозволяють перенаправляти певні порти на віддаленому сервері або локально. Це дуже зручно, коли нам потрібно потрапити на конкретний сервер у локальній мережі.\nТехнічно є можливість перенаправляти можна як локальні, так і віддалені порти. Ми розглянемо обидва випадки.\nПеренаправлення локального порта Розглянемо ситуацію, коли ми перебуваємо всередині локальної мережі, де доступ в інтернет блокується фаєрволлом усім, крім одного сервера, що має прямий доступ до інтернету. У нас є доступ до цього сервера SSH. Наше завдання полягає в тому, щоб підключитися до віддаленого сервера, який знаходиться у зовнішній мережі SSH.\nРозглянемо приклад:\nssh -f -N -L 2222:212.212.212.212:22 user@111.111.111.111 Ця команда створить тунель, прокинувши порт 22 віддаленого сервера через локальний сервер, і ми зможемо підключитися до віддаленого сервера через порт 2222, який слухатиметься на локальному інтерфейсі нашого ПК.\nЗалишаємо термінал із тунельною сесією запущеним, у новому терміналі підключаємося до віддаленого сервера командою:\nssh -p2222 127.0.0.1 Таким чином, ми отримали доступ до SSH віддаленого сервера.\nПеренаправлення віддаленого порту Цей випадок протилежний до перенаправлення локального порта. Розглянемо ту ж саму локальну мережу і віддалений сервер, тільки тепер у локального ПК є доступ до Інтернету через NAT. Припустимо, що системному адміністратору, який має фізичний доступ до віддаленого сервера, потрібно підключитися по RDP до комп\u0026rsquo;ютера 192.168.0.2, але NAT не дасть цього зробити безпосередньо.\nРозглянемо приклад, де існує RDP сервіс, що за змовчанням запущено на локальному порту 3389. Прокидаємо його на віддалений порт 3333.\nssh -f -N -R 3333:127.0.0.1:3389 username@212.212.212.212 Після підняття такого тунелю, сисадмін, що сидить за віддаленим сервером, зможе до нас підключитися RDP, використовуючи в RDP клієнті адресу 127.0.0.1:3333.\nВисновки Ось такі прості прийоми тунелювання через SSH протокол дозволяють маючи в розпорядженні доступ по SSH, перенаправляти порти локального чи віддаленого сервісу як заманеться, що може стати в нагоді якщо треба обійти певні обмеження в мережі, як, наприклад NAT.\n","date":"2016-09-26T00:00:00Z","image":"http://localhost:1313/post/port-forwarding-using-an-ssh-tunnel/header_hu9370f1f3ff0baab462d9f98d73fd8fc5_63678_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"http://localhost:1313/uk/post/%D0%BF%D0%B5%D1%80%D0%B5%D0%BD%D0%B0%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F-%D0%BF%D0%BE%D1%80%D1%82%D1%96%D0%B2-%D0%B7%D0%B0-%D0%B4%D0%BE%D0%BF%D0%BE%D0%BC%D0%BE%D0%B3%D0%BE%D1%8E-ssh-%D1%82%D1%83%D0%BD%D0%B5%D0%BB%D1%8E/","title":"Перенаправлення портів за допомогою SSH тунелю"}]